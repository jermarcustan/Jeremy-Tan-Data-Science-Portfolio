{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla MLP\n",
    "\n",
    "by Jeremy Tan, Benjamin Ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ucimlrepo\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "\n",
    "# Data Handling and Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "# Dataset Fetching\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n"
     ]
    }
   ],
   "source": [
    "# Fetch Dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), \n",
    "                        columns=X.columns, \n",
    "                        index=X.index)\n",
    "# Assign the value of 1 to Malignant, assign 0 to Benign\n",
    "Y.loc[:, 'Diagnosis'] = Y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)  # Shows first 5 and last 5 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>...</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>...</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius1  texture1  perimeter1     area1  smoothness1  ...  concavity3  \\\n",
       "0    1.097064 -2.073335    1.269934  0.984375     1.568466  ...    2.109526   \n",
       "1    1.829821 -0.353632    1.685955  1.908708    -0.826962  ...   -0.146749   \n",
       "2    1.579888  0.456187    1.566503  1.558884     0.942210  ...    0.854974   \n",
       "3   -0.768909  0.253732   -0.592687 -0.764464     3.283553  ...    1.989588   \n",
       "4    1.750297 -1.151816    1.776573  1.826229     0.280372  ...    0.613179   \n",
       "..        ...       ...         ...       ...          ...  ...         ...   \n",
       "564  2.110995  0.721473    2.060786  2.343856     1.041842  ...    0.664512   \n",
       "565  1.704854  2.085134    1.615931  1.723842     0.102458  ...    0.236573   \n",
       "566  0.702284  2.045574    0.672676  0.577953    -0.840484  ...    0.326767   \n",
       "567  1.838341  2.336457    1.982524  1.735218     1.525767  ...    3.197605   \n",
       "568 -1.808401  1.221792   -1.814389 -1.347789    -3.112085  ...   -1.305831   \n",
       "\n",
       "     concave_points3  symmetry3  fractal_dimension3  Diagnosis  \n",
       "0           2.296076   2.750622            1.937015          1  \n",
       "1           1.087084  -0.243890            0.281190          1  \n",
       "2           1.955000   1.152255            0.201391          1  \n",
       "3           2.175786   6.046041            4.935010          1  \n",
       "4           0.729259  -0.868353           -0.397100          1  \n",
       "..               ...        ...                 ...        ...  \n",
       "564         1.629151  -1.360158           -0.709091          1  \n",
       "565         0.733827  -0.531855           -0.973978          1  \n",
       "566         0.414069  -1.104549           -0.318409          1  \n",
       "567         2.289985   1.919083            2.219635          1  \n",
       "568        -1.745063  -0.048138           -0.751207          0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset = pd.concat([X, Y], axis=1)\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0            357\n",
       "1            212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Custom PyTorch Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        # Convert NumPy array to a PyTorch tensor\n",
    "        self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
    "        self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples (n)\n",
    "        return self.data_x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the m-dimensional data point at index `idx`\n",
    "        return self.data_x[idx], self.data_y[idx]\n",
    "\n",
    "# Get the numpy values from df x and y\n",
    "x_train = X_train.values.astype(np.float32)\n",
    "y_train = Y_train.values.astype(np.float32)\n",
    "\n",
    "# Create the training dataset\n",
    "training_dataset = CustomDataset(x_train, y_train)\n",
    "\n",
    "# Example usage with DataLoader\n",
    "train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of training dataset\n",
    "x1,y1 = next(iter(train_loader))\n",
    "print(x1.shape)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "  # Constructor\n",
    "    def __init__(self, in_dimensions, out_dimensions):\n",
    "        super().__init__()\n",
    "        self.in_dimensions = in_dimensions\n",
    "        self.out_dimensions = out_dimensions\n",
    "\n",
    "        self.input_to_hidden_a = torch.nn.Linear(self.in_dimensions, 10)\n",
    "        self.hidden_a_to_b = torch.nn.Linear(10, 7)\n",
    "        self.hidden_b_to_output = torch.nn.Linear(7, self.out_dimensions)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_to_hidden_a.forward(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.hidden_a_to_b.forward(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.hidden_b_to_output.forward(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5664],\n",
      "        [0.5718]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MultiLayerPerceptron(30,1)\n",
    "\n",
    "x = torch.rand(2, 30)\n",
    "\n",
    "y = model.forward(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.7078\n",
      "Epoch [2/20], Loss: 0.7051\n",
      "Epoch [3/20], Loss: 0.7010\n",
      "Epoch [4/20], Loss: 0.6964\n",
      "Epoch [5/20], Loss: 0.6928\n",
      "Epoch [6/20], Loss: 0.6880\n",
      "Epoch [7/20], Loss: 0.6842\n",
      "Epoch [8/20], Loss: 0.6790\n",
      "Epoch [9/20], Loss: 0.6752\n",
      "Epoch [10/20], Loss: 0.6704\n",
      "Epoch [11/20], Loss: 0.6671\n",
      "Epoch [12/20], Loss: 0.6617\n",
      "Epoch [13/20], Loss: 0.6572\n",
      "Epoch [14/20], Loss: 0.6531\n",
      "Epoch [15/20], Loss: 0.6472\n",
      "Epoch [16/20], Loss: 0.6417\n",
      "Epoch [17/20], Loss: 0.6353\n",
      "Epoch [18/20], Loss: 0.6328\n",
      "Epoch [19/20], Loss: 0.6252\n",
      "Epoch [20/20], Loss: 0.6211\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Define the model\n",
    "# 30 input features\n",
    "model = MultiLayerPerceptron(30, 1)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# List to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Append the average loss to the loss_values list\n",
    "    loss_values.append(avg_loss)\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to PyTorch tensors (if not already)\n",
    "x_test = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "y_test = torch.tensor(Y_test.values.astype(np.float32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.88      0.96      0.92        71\n",
      "   Malignant       0.92      0.79      0.85        43\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.90      0.87      0.88       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get predictions\n",
    "    test_predictions = model(x_test)\n",
    "    test_predictions_binary = (test_predictions > 0.5).numpy().flatten()\n",
    "    \n",
    "# Convert test labels to numpy\n",
    "y_test_binary = y_test.flatten()\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, test_predictions_binary)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_binary, test_predictions_binary, \n",
    "                             target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "Parameters:\n",
    "1. Learning Rate\n",
    "2. Number of neurons in the hidden layers - hidden1, hidden2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, in_dimensions, out_dimensions, hidden1, hidden2):\n",
    "        super().__init__()\n",
    "        self.input_to_hidden_a = nn.Linear(in_dimensions, hidden1)\n",
    "        self.hidden_a_to_b = nn.Linear(hidden1, hidden2)\n",
    "        self.hidden_b_to_output = nn.Linear(hidden2, out_dimensions)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_to_hidden_a(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.hidden_a_to_b(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.hidden_b_to_output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    hidden1 = trial.suggest_categorical('hidden1', [8, 10, 16])\n",
    "    hidden2 = trial.suggest_categorical('hidden2', [6, 7, 14])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train.values.astype(np.float32), dtype = torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.astype(np.float32), dtype = torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val.values.astype(np.float32), dtype = torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values.astype(np.float32), dtype = torch.float32)\n",
    "    \n",
    "    # Create model, loss, and optimizer\n",
    "    model = MultiLayerPerceptron(30, 1, hidden1, hidden2)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create the training dataset\n",
    "    training_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # Example usage with DataLoader\n",
    "    train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_preds = (val_outputs > 0.5).float()\n",
    "        accuracy = accuracy_score(y_val, val_preds.numpy())\n",
    "        auc = roc_auc_score(y_val, val_outputs.numpy())\n",
    "    \n",
    "    # Report multiple metrics\n",
    "    trial.set_user_attr('accuracy', accuracy)\n",
    "    trial.set_user_attr('auc', auc)\n",
    "    \n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "[I 2024-12-05 17:33:32,405] A new study created in memory with name: Breast Cancer Classifier Optimization\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:32,763] Trial 0 finished with value: 0.25157707929611206 and parameters: {'hidden1': 8, 'hidden2': 14, 'learning_rate': 0.0005743295953426758}. Best is trial 0 with value: 0.25157707929611206.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:33,129] Trial 1 finished with value: 0.2751288115978241 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.0004367022239999229}. Best is trial 0 with value: 0.25157707929611206.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:33,486] Trial 2 finished with value: 0.12325435131788254 and parameters: {'hidden1': 8, 'hidden2': 7, 'learning_rate': 0.003359097049116835}. Best is trial 2 with value: 0.12325435131788254.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:33,889] Trial 3 finished with value: 0.17701148986816406 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0006646738769904626}. Best is trial 2 with value: 0.12325435131788254.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:34,266] Trial 4 finished with value: 0.15558652579784393 and parameters: {'hidden1': 16, 'hidden2': 6, 'learning_rate': 0.004328986742640568}. Best is trial 2 with value: 0.12325435131788254.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:34,641] Trial 5 finished with value: 0.6450909972190857 and parameters: {'hidden1': 16, 'hidden2': 7, 'learning_rate': 0.00016115073714501903}. Best is trial 2 with value: 0.12325435131788254.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:34,996] Trial 6 finished with value: 0.11663661152124405 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0012843255292612301}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:35,371] Trial 7 finished with value: 0.2521156966686249 and parameters: {'hidden1': 8, 'hidden2': 6, 'learning_rate': 0.000744661226395316}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:35,738] Trial 8 finished with value: 0.13738200068473816 and parameters: {'hidden1': 8, 'hidden2': 6, 'learning_rate': 0.001377061728473446}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:36,119] Trial 9 finished with value: 0.48843011260032654 and parameters: {'hidden1': 8, 'hidden2': 6, 'learning_rate': 0.00036946621547683943}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:36,506] Trial 10 finished with value: 0.2217531055212021 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.008082242317687005}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:36,893] Trial 11 finished with value: 0.12641042470932007 and parameters: {'hidden1': 10, 'hidden2': 7, 'learning_rate': 0.002236352490717418}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:37,276] Trial 12 finished with value: 0.1298130601644516 and parameters: {'hidden1': 10, 'hidden2': 7, 'learning_rate': 0.002485698443987029}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:37,645] Trial 13 finished with value: 0.22033679485321045 and parameters: {'hidden1': 8, 'hidden2': 7, 'learning_rate': 0.00854900110712823}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:38,045] Trial 14 finished with value: 0.1222076341509819 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0015116825831519212}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:38,426] Trial 15 finished with value: 0.12428715825080872 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0012770584290583697}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:38,801] Trial 16 finished with value: 0.5695604085922241 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0002203065070381486}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:39,175] Trial 17 finished with value: 0.12176481634378433 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0015065820402518353}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:39,552] Trial 18 finished with value: 0.17671753466129303 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.005320330822984696}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:39,917] Trial 19 finished with value: 0.11839267611503601 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.002020128139365309}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:40,270] Trial 20 finished with value: 0.20917978882789612 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0009645501537957092}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:40,637] Trial 21 finished with value: 0.12600606679916382 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0020886458433555565}. Best is trial 6 with value: 0.11663661152124405.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:40,999] Trial 22 finished with value: 0.11527663469314575 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0017582961268441416}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:41,365] Trial 23 finished with value: 0.16701529920101166 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0030466741324387215}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:41,727] Trial 24 finished with value: 0.1267402172088623 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0009638014473176713}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:42,077] Trial 25 finished with value: 0.12339191138744354 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.001831396907231622}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:42,449] Trial 26 finished with value: 0.14488312602043152 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.005433934649464906}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:42,815] Trial 27 finished with value: 0.1449945569038391 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.003391375720956064}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:43,183] Trial 28 finished with value: 0.5512272119522095 and parameters: {'hidden1': 10, 'hidden2': 6, 'learning_rate': 0.00030476103445822373}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:43,580] Trial 29 finished with value: 0.15305815637111664 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.0005224432233333128}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:43,973] Trial 30 finished with value: 0.13645829260349274 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0008355807505528133}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:44,368] Trial 31 finished with value: 0.12889893352985382 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0013057596455057967}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:44,749] Trial 32 finished with value: 0.12342473864555359 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.001768567800445893}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:45,115] Trial 33 finished with value: 0.12283045053482056 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0011918071575419337}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:45,481] Trial 34 finished with value: 0.2610659897327423 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.0005793946203048304}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:45,840] Trial 35 finished with value: 0.13550297915935516 and parameters: {'hidden1': 10, 'hidden2': 14, 'learning_rate': 0.003016349746001794}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:46,215] Trial 36 finished with value: 0.16554616391658783 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.004035301306967571}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:46,600] Trial 37 finished with value: 0.12980830669403076 and parameters: {'hidden1': 10, 'hidden2': 7, 'learning_rate': 0.0024155038453188616}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:46,972] Trial 38 finished with value: 0.6900960803031921 and parameters: {'hidden1': 8, 'hidden2': 6, 'learning_rate': 0.00010059606663195708}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:47,368] Trial 39 finished with value: 0.12097030133008957 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.001618050571788013}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:47,786] Trial 40 finished with value: 0.17252691090106964 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.0008093486660973301}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:48,209] Trial 41 finished with value: 0.1275576800107956 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.0016332431397257745}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:48,605] Trial 42 finished with value: 0.12739765644073486 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.001881981835539126}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:48,997] Trial 43 finished with value: 0.12070301175117493 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.001008828400967299}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:49,363] Trial 44 finished with value: 0.13909484446048737 and parameters: {'hidden1': 16, 'hidden2': 6, 'learning_rate': 0.0011217772011876473}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:49,734] Trial 45 finished with value: 0.12652446329593658 and parameters: {'hidden1': 16, 'hidden2': 7, 'learning_rate': 0.0027311260785846483}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:50,121] Trial 46 finished with value: 0.26657265424728394 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.0007007111875856687}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:50,502] Trial 47 finished with value: 0.2114337831735611 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.00045383418020471277}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:50,888] Trial 48 finished with value: 0.20191189646720886 and parameters: {'hidden1': 8, 'hidden2': 7, 'learning_rate': 0.0009981848979560056}. Best is trial 22 with value: 0.11527663469314575.\n",
      "<ipython-input-38-fd7def23e6e1>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "<ipython-input-14-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-14-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 17:33:51,271] Trial 49 finished with value: 0.12075269222259521 and parameters: {'hidden1': 16, 'hidden2': 14, 'learning_rate': 0.001453628969800308}. Best is trial 22 with value: 0.11527663469314575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (Val Loss): 0.11527663469314575\n",
      "  Params: \n",
      "    hidden1: 10\n",
      "    hidden2: 14\n",
      "    learning_rate: 0.0017582961268441416\n",
      "\n",
      "Best Trial Metrics:\n",
      "  Accuracy: 0.9736842105263158\n",
      "  AUC: 0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "# Assign the value of 1 to Malignant, assign 0 to Benign\n",
    "Y.loc[:, 'Diagnosis'] = Y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), \n",
    "                        columns=X.columns, \n",
    "                        index=X.index)\n",
    "\n",
    "# Split the data - 60/20/20 Train Validation Test Split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', \n",
    "                             study_name='Vanilla MLP Optimization')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (Val Loss): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Print additional metrics from the best trial\n",
    "print(\"\\nBest Trial Metrics:\")\n",
    "print(f\"  Accuracy: {trial.user_attrs['accuracy']}\")\n",
    "print(f\"  AUC: {trial.user_attrs['auc']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the best trial's parameters\n",
    "best_params = study.best_trial.params\n",
    "best_hidden_dim_1 = best_params['hidden1']\n",
    "best_hidden_dim_2 = best_params['hidden2']\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "\n",
    "# Create the model with the best hyperparameters\n",
    "best_model = MultiLayerPerceptron(30, 1, best_hidden_dim_1, best_hidden_dim_2)\n",
    "\n",
    "# Convert train and validation data to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Create optimizer with the best learning rate\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Retrain the model with best hyperparameters\n",
    "# Batching is not implemented. \n",
    "# The whole training dataset is processed in a single pass. \n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = best_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Convert test data to tensors\n",
    "X_test_tensor = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predictions\n",
    "    test_outputs = best_model(X_test_tensor)\n",
    "    test_preds = (test_outputs > 0.5).float()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds.numpy())\n",
    "    test_auc = roc_auc_score(y_test, test_outputs.numpy())\n",
    "    \n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_preds.numpy())\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, test_preds.numpy())\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "Test Loss: 0.6020647883415222\n",
      "Test Accuracy: 0.9473684210526315\n",
      "Test AUC: 0.9927939731411726\n",
      "\n",
      "Confusion Matrix:\n",
      "[[69  2]\n",
      " [ 4 39]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        71\n",
      "           1       0.95      0.91      0.93        43\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test AUC: {test_auc}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
