{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention-Free Transformer\n",
    "\n",
    "by Jeremy Tan, Benjamin Ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ucimlrepo\n",
    "# !pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "# Data Handling and Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "# Dataset Fetching\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n"
     ]
    }
   ],
   "source": [
    "# Fetch Dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), \n",
    "                        columns=X.columns, \n",
    "                        index=X.index)\n",
    "# Assign the value of 1 to Malignant, assign 0 to Benign\n",
    "Y.loc[:, 'Diagnosis'] = Y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape is (455, 30)\n",
      "X test shape is (114, 30)\n",
      "Y train shape is (455, 1)\n",
      "Y test shape is (114, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X train shape is {X_train.shape}\")\n",
    "print(f\"X test shape is {X_test.shape}\")\n",
    "print(f\"Y train shape is {Y_train.shape}\")\n",
    "print(f\"Y test shape is {Y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0            357\n",
       "1            212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Custom PyTorch Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        # Convert NumPy array to a PyTorch tensor\n",
    "        self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
    "        self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples (n)\n",
    "        return self.data_x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the m-dimensional data point at index `idx`\n",
    "        return self.data_x[idx], self.data_y[idx]\n",
    "\n",
    "# Get the numpy values from df x and y\n",
    "x_train = X_train.values.astype(np.float32)\n",
    "y_train = Y_train.values.astype(np.float32)\n",
    "\n",
    "# Create the training dataset\n",
    "training_dataset = CustomDataset(x_train, y_train)\n",
    "\n",
    "# Example usage with DataLoader\n",
    "train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFTSimple(nn.Module):\n",
    "    def __init__(self, max_seqlen, dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.to_q = nn.Linear(dim, hidden_dim)\n",
    "        self.to_k = nn.Linear(dim, hidden_dim)\n",
    "        self.to_v = nn.Linear(dim, hidden_dim)\n",
    "        self.project = nn.Linear(hidden_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, _ = x.shape\n",
    "        Q = self.to_q(x).view(B, T, self.hidden_dim)\n",
    "        K = self.to_k(x).view(B, T, self.hidden_dim)\n",
    "        V = self.to_v(x).view(B, T, self.hidden_dim)\n",
    "\n",
    "        weights = torch.mul(torch.softmax(K, 1), V).sum(dim=1, keepdim=True)\n",
    "        Q_sig = torch.sigmoid(Q)\n",
    "        Yt = torch.mul(Q_sig, weights)\n",
    "\n",
    "        Yt = Yt.view(B, T, self.hidden_dim)\n",
    "        Yt = self.project(Yt)\n",
    "\n",
    "        return Yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BreastCancerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=30, hidden_dim=64, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # AFT-style layer\n",
    "        self.aft_layer = AFTSimple(max_seqlen=input_dim, dim=input_dim, hidden_dim=hidden_dim)\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim),\n",
    "            nn.Sigmoid()  # For binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # If input is 2D (batch, features), add a dummy sequence dimension\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)  # Add sequence dimension: (batch, 1, features)\n",
    "        \n",
    "        # Pass through AFT layer\n",
    "        x = self.aft_layer(x)\n",
    "        \n",
    "        \n",
    "        # Squeeze out the sequence dimension if it exists\n",
    "        x = x.squeeze(1) if x.dim() > 2 else x\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        return self.fc_layers(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = BreastCancerClassifier(input_dim=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: tensor([[0.4687],\n",
      "        [0.4692]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test model with input\n",
    "model = BreastCancerClassifier()\n",
    "x_trial = torch.rand(2, 30)\n",
    "y_trial = model(x_trial)\n",
    "print(\"Final output:\", y_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6937\n",
      "Epoch [2/20], Loss: 0.6850\n",
      "Epoch [3/20], Loss: 0.6759\n",
      "Epoch [4/20], Loss: 0.6666\n",
      "Epoch [5/20], Loss: 0.6537\n",
      "Epoch [6/20], Loss: 0.6398\n",
      "Epoch [7/20], Loss: 0.6224\n",
      "Epoch [8/20], Loss: 0.6007\n",
      "Epoch [9/20], Loss: 0.5729\n",
      "Epoch [10/20], Loss: 0.5389\n",
      "Epoch [11/20], Loss: 0.4964\n",
      "Epoch [12/20], Loss: 0.4508\n",
      "Epoch [13/20], Loss: 0.4037\n",
      "Epoch [14/20], Loss: 0.3550\n",
      "Epoch [15/20], Loss: 0.3100\n",
      "Epoch [16/20], Loss: 0.2666\n",
      "Epoch [17/20], Loss: 0.2334\n",
      "Epoch [18/20], Loss: 0.2096\n",
      "Epoch [19/20], Loss: 0.2083\n",
      "Epoch [20/20], Loss: 0.1631\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debyUZf3/8deHTUFcUAs3OKhZ5pYpuZQLKC5QipqldtQ0jbS0/LobWVbS17LU3EJcMpPCvi5pgksuuJSmkmiaS2aAKO6mIIoi1++Pa/jN8TgHDnhm7plzXs/H436cmWvuM/OZiznnvLnv676uSCkhSZKk2upWdAGSJEldkSFMkiSpAIYwSZKkAhjCJEmSCmAIkyRJKoAhTJIkqQCGMEkVRcQNEfHVjt5X9SsiDoqIu4uuQ+oqDGFSJxIRc1psCyLirRb3m5fkuVJKw1NKv+nofZdERAyJiJkd/bztfO2IiOMi4l+lfpwREadFxDI1ev0hpX/DOa22rWvx+pKqr0fRBUjqOCmlvgtvR8Q04NCU0i2t94uIHiml+bWsrQGdDewKHAjcD3wC+DXwSWBkR77QIv49nksprdWRryWpfngkTOoCFh5RiogTIuJ54NcR0S8iro+IlyLitdLttVp8z+SIOLR0+6CIuDsifl7a9z8RMXwp9107Iu6MiNkRcUtEnBcRly/Fe/pk6XX/GxGPRsTuLR4bERH/LL3GsxFxbKl91dL7/G9EvBoRd0XEB34PRsR6wDeB5pTSPSml+SmlR4EvArtGxA4RsVVEPB8R3Vt8354R8XDpdreIODEi/h0Rr0TEHyJi5dJjgyIiRcQhETEDuG0p3v/kiPjfiLgvIl6PiGsXPn/p8d1L/fLf0r6fbPHYgIi4uvRv/0pEnNvqudv6tzsoIp4u9et/lvToqqT3M4RJXcdqwMpAEzCK/PP/69L9gcBbwLltfjdsCTwBrAr8DLg4ImIp9v0dcB+wCnAKcMCSvpGI6An8CbgZ+ChwJDA+Ij5R2uVi4BsppeWBjSiHnGOAmcBHgP7Ad4FKa7ftCMxMKd3XsjGl9AxwL7BTSule4E1ghxa7fKX0/gC+DewBbA+sAbwGnNfqdbYnH1nbpb3vvZUDga+Vnn8++egdEfFx4PfAUeT3Ogn4U0T0KoXG64HpwCBgTWBCi+es+G8XEcuVnn94qV8/C0xdyrolYQiTupIFwA9SSvNSSm+llF5JKV2VUpqbUpoNjCGHgrZMTyldmFJ6D/gNsDo5yLR734gYCHwG+H5K6Z2U0t3AdUvxXrYC+gKnlZ7nNnKw2K/0+LvABhGxQkrptZTS31u0rw40pZTeTSndlSovoLsqMKuN155Vehxy0NkPICKWB0aU2gC+AYxOKc1MKc0jB869I6LlMJBTUkpvppTeauO11igdyWq5Ldfi8d+mlB5JKb0JnAx8uRSy9gEmppT+nFJ6F/g50JscnLYgh7bjSq/9dunfYaFF/TsvADaKiN4ppVmlo4OSlpIhTOo6Xkopvb3wTkT0iYgLImJ6RLwB3Ams1PL0WivPL7yRUppbutl3CfddA3i1RRvAM0v4Pig9zzMppQUt2qaTj+pAPm04ApgeEXdEeTD76cBTwM2l02ontvH8L5PDRyWrlx6HfNRrr8iD9fcC/p5Sml56rAm4ZmF4Ah4D3uP9wXVx7/25lNJKrbY32/j+6UBPckBco3QfgFI/PUPunwHkoNXWmMCK/3al190HOAyYFRETI2L9xdQvaREMYVLX0fqIzzHkweZbppRWALYrtbd1irEjzAJWjog+LdoGLMXzPAcMaDWeayDwLEBK6f6U0kjyqco/An8otc9OKR2TUloH2A04OiJ2rPD8t5Wef4uWjRExgHwU7tbS8/2THHaG8/5TkZBDz/BWAWrZlNKzLfapdBRuSbTsu4HkI30vk/unqUXdUdr32VJdA1sdkWuXlNJNKaWdyEH0ceDCpS9dkiFM6rqWJ48D+29pQPcPqv2CpaNEDwCnlMYnbU0OQ4sUEcu23Mhjyt4Ejo+InhExpPQ8E0rP2xwRK5ZOxb1BPgJFRHwhIj5WCiUL29+rUOeTwFjyOLOtIqJ7RGwIXAXc0uqK09+Rx39tB/xfi/axwJiIaCq99kciokOvqgT2j4gNSqH2R8CVpdOIfwA+HxE7lsbPHQPMA/5K7rtZwGkRsVypTz+3uBeKiP6lwf7LlZ5rDhX6TlL7GcKkruss8jihl8mDzW+s0es2A1sDrwCnAleQ/6i3ZU1yWGy5DQB2Jx+Behk4HzgwpfR46XsOAKaVTrMeBuxfal8PuIUcIO4Bzk8pTW7jdY8ALgIuL+1/IzCZfKqzpd8DQ4DbUkovt2j/JXm8280RMZvcx1su4n1WskZ8cJ6wlq//W+BS8inEZclhkJTSE+T3fA65f3YDdiuNn3uvdP9jwAzyhQr7tKOWbuQw9xzwKnn84DeX8P1IaiEqj0mVpNqIiCuAx1NKVT8S15lExGTg8pTSRUXXImnpeCRMUk1FxGciYt3SPFq7kic+/WPRdUlSrTljvqRaWw24mjxP2Ezg8JTSg8WWJEm15+lISZKkAng6UpIkqQCGMEmSpAI03JiwVVddNQ0aNKjoMgr35ptvstxyyy1+x07OfiizL8rsizL7IrMfyuyLslr0xZQpU15OKX2k0mMNF8IGDRrEAw88UHQZhZs8eTJDhgwpuozC2Q9l9kWZfVFmX2T2Q5l9UVaLvoiI6W095ulISZKkAhjCJEmSCmAIkyRJKoAhTJIkqQCGMEmSpAIYwiRJkgpQ1RAWEbtGxBMR8VREnFjh8eMiYmppeyQi3ouIlatZkyRJUj2oWgiLiO7AecBwYANgv4jYoOU+KaXTU0qbppQ2BU4C7kgpvVqtmiRJkupFNY+EbQE8lVJ6OqX0DjABGLmI/fcDfl/FeiRJkupGpJSq88QRewO7ppQOLd0/ANgypXREhX37ADOBj1U6EhYRo4BRAP379998woQJVakZ4JZbPspFF63Diy8uw0c/Oo9DD32aYcNerNrrLa05c+bQt2/fossonP1QZl+U2Rdl9kVmP5TZF2W16IuhQ4dOSSkNrvRYNZctigptbSW+3YC/tHUqMqU0DhgHMHjw4FStJQbGj4czz4S5c/P9F15YljPP3IBPfnIDmpur8pJLzWUnMvuhzL4osy/K7IvMfiizL8qK7otqno6cCQxocX8t4Lk29t2XOjgVOXp0OYAtNHdubpckSepI1Qxh9wPrRcTaEdGLHLSua71TRKwIbA9cW8Va2mXGjMrt06fDuHFw773w5pu1rUmSJHVOVTsdmVKaHxFHADcB3YFLUkqPRsRhpcfHlnbdE7g5pVR4vBk4MAeu1iLgG98o3/7Yx2CTTeBTn8rbJptAU1N+TJIkqT2qOSaMlNIkYFKrtrGt7l8KXFrNOtprzBgYNer9pyT79MlHwT77WXj4YXjoofJ21VXl/VZY4YPBbKONYLnlKr/W+PH5NOeMGTn8jRlD3Y07kyRJ1VPVENZoFoagtsLR2mvDyBaTbMyZA488Ug5lDz8Ml10Gs2fnxyNgvfU+GM7uvvv9YW/69Hy/ZQ2SJKlzM4S10tzc/iDUty9stVXeFlqwAKZNKx81e/hhePBBuPLK8j4R0HpmkIUXABjCJEnqGgxhHaxbN1hnnbztsUe5ffbs8lGzww+v/L3Tp8NBB8Fmm8GnP52PnK2wQk3KliRJNWYIq5Hll4ett87baadVvgBg2WXhxhvhN78pt33sYzmQtdz6969d3ZIkqTqquoC3KhszJg/4b6lPH7joInj+eXjuOZg4EU49NR8NmzIFvvtdGD4cVlsN1lgDTjxxY04+Ga6+Gv7znw+e3mxp/HgYNCgfpRs0KN+XJEnF8khYARZ3AcDqq+dtxIjy9/z3vzB1ah5f9uCDcPfdy/C//wvvvZcfX2kl2HTT9x8xW399uOIKLwKQJKkeGcIKsiQXAEAOWUOG5A1g8uQH2HLLITzySDmY/f3v8Ktfwdtv532WXTZfKPDOO+9/Li8CkCSpeIawBta7N3zmM3lbaP58eOKJcjA744zK3zt9el4nc7PN8hG0FVesTc2SJCkzhHUyPXrAhhvmbf/984SylS4C6NYNjj66fH+ddcpXZX760/m2FwBIklQ9hrBOblGrAAwbVj6NufBry/nMVl/9g8HM5ZkkSeoYhrBObnEXAey6a94Wev31fAHAwmD24INwww15bBlAv3759GXLcPaJT0D37vlxl2OSJKl9DGFdwJJcBLDiirD99nlb6K234B//eH8wO/dcmDcvP96nT16Oabnl4K67yhcCeCWmJEltM4RpsXr3hi22yNtC774Ljz/+/tOZt91WeTmm44+Hr3zF05iSJLVkCNNS6dkTNt44bwcemNu6tTH173PP5cXPd9opbzvuCKusUrtaJUmqR86Yrw4zcGDl9n798tixP/wB9tkHPvIRGDwYTjoJbr+9fFpTkqSuxBCmDtPWckznnAPXXAOvvAJ//Succko+xfnzn8MOO8DKK+clmc44I489W9QSTJIkdRaejlSHWdyVmD16lBcx//73YfZsmDwZ/vznvB1zTN5vtdXy9BkLT1+uvnohb0eSpKoyhKlDLcmVmMsvD7vtljeAZ56BW27Jgeymm+Dyy3P7hhuWA9n22+erMMtTYWzvVBiSpIZkCFPdGDAADj44bwsWwEMPlY+S/epXcNZZ+YKAj30MnnoqX6EJ4VQYkqSG5Jgw1aVu3fJg/uOPzyHstdfg5pvhqKNaBrCyuXPhxBOLqVWSpKVhCFND6N07n4782c/yIuWVzJwJn/sc/OQnedZ/B/hLkuqZIUwNp62pMFZcMc/WP3p0Poo2YEA+TXnttTBnTm1rlCRpcQxhajhtTYVx3nlw//0waxZcckm+CvOKK2CPPfLksDvvDL/8ZT6dKUlS0QxhajjNzTBuHDQ1QUSiqSnfXzgof7XV8uD+//s/eOmlvJzSkUfmqy+POgrWWy8vOn700flqzIVrXUqSVEuGMDWk5maYNg1uu+0Opk1r+6rIXr1g6NA8Mexjj8G//50nj11nHTj//DzObJVVYK+94OKL8xJLkiTVgiFMXco668ARR8ANN+QZ/K+7Lge4+++HQw+FNdeEzTaDk0+Ge++F997Lc5INGpSv2Bw0KN+XJOnDcp4wdVnLLVeeLDYleOQRmDgxbz/5CZx6KvTtC2+9lcMY4JxkkqQO45EwCYiAjTfOc43ddVceS/b73+dwtjCALTR3Lnz3u8XUKUnqPAxhUgUrrwz77psDVyUzZuTB/vfd53xkkqSlYwiTFqGtOcn69IELL4Qtt4T118/TZkyfXtvaJEmNzRAmLUJbc5KNGwcvvAAXXZSnxPje9/Kg/SFD8lWWr79eRLWSpEZiCJMW4f1zkvG+OclWXBEOOQTuuAP+8588kH/WrHyV5Wqr5dOZEyd+cJ1LSZLAECYt1sI5yRYsoM05yQYNysslPf44/O1vOZzdcgt84Quw1lp5ktgpUxw/JkkqM4RJHSgCttgCzj03T/x67bWw7bbwq1/B4MGw0UZw2ml59n5JUtdmCJOqpFcv2H13uPJKeP55GDsW+vWDk07KpzV33BEuvRRmzy5/jxPDSlLXYQiTaqBfP/jGN+Duu/MC4j/4Qb6a8uCDoX//fIrz+OPzRLDTp+fTlgsnhjWISVLnZAiTamzddXMI+9e/4K9/ha9+NS+jdPrpH5yXbO7cPNZMktT5GMKkgkTA1lvn8WKzZuX7lcyYUdu6JEm1YQiT6sAyy7Q9MWzPnvCHP8D8+bWtSZJUXYYwqU5Umhi2Vy9YaSXYZx9Ybz04+2yYM6eY+iRJHcsQJtWJShPDXnJJnurimmtgzTXhO9+BAQPyAuKzZhVdsSTpwzCESXWk0sSw3bvDHnvkKyvvuQeGDYOf/jSHtK99DR55pOiqJUlLwxAmNZCttoL/+z948sk85cUVV8DGG8Pw4TBlykrOyC9JDcQQJjWgddeFc87JV06eeio8+CAce+ymbLZZnlfM9Solqf4ZwqQGtsoqeR6xadPguOMeZ9482H9/WGcd+MUv4PXXi65QktQWQ5jUCSy7LIwY8TyPPAITJ+YrKY89Ng/iP/ZY16qUpHpU1RAWEbtGxBMR8VREnNjGPkMiYmpEPBoRd1SzHqmz69YNRoyA226DBx6AL3wBzjorHxnbf/982hJco1KS6kHVQlhEdAfOA4YDGwD7RcQGrfZZCTgf2D2ltCHwpWrVI3U1m28Ov/sdPP00fPvbcO21sNlmsOGGcMghrlEpSUWr5pGwLYCnUkpPp5TeASYAI1vt8xXg6pTSDICU0otVrEfqkgYOzOPDnnkGfvYzeOIJmDfv/fu4RqUk1V41Q9iaQMuRKDNLbS19HOgXEZMjYkpEHFjFeqQubaWV4Ljj8hxklbhGpSTVVqQqTSwUEV8CdkkpHVq6fwCwRUrpyBb7nAsMBnYEegP3AJ9PKT3Z6rlGAaMA+vfvv/mECROqUnMjmTNnDn379i26jMLZD2Xt7Yt9992KF15Y9gPtyyzzHpdeeh+rrTavwnc1Fj8XZfZFZj+U2RdlteiLoUOHTkkpDa70WI8qvu5MYECL+2sBz1XY5+WU0pvAmxFxJ/Ap4H0hLKU0DhgHMHjw4DRkyJBq1dwwJk+ejP1gP7TU3r74xS/yGLC5c8ttPXvCggXdOfjgrTnhBDj++A+uY9lI/FyU2ReZ/VBmX5QV3RfVPB15P7BeRKwdEb2AfYHrWu1zLbBtRPSIiD7AlsBjVaxJ6vIqrVH561/Dv/+dl0f64Q/hk5/MM/M7A78kVU/VQlhKaT5wBHATOVj9IaX0aEQcFhGHlfZ5DLgReBi4D7gopeRKeFKVVVqjcsAA+P3v4Y47oF8/+PKXYehQePjhoquVpM6pqvOEpZQmpZQ+nlJaN6U0ptQ2NqU0tsU+p6eUNkgpbZRSOqua9UhavO22gylTYOzYvDj4pz8N3/wmvPJK0ZVJUufijPmSPqB797xA+L/+Bd/6Vj59ud56cP75MH9+0dVJUudgCJPUpn794OyzYerUfETsW9/KE75Onlx0ZZLU+AxhkhZro43gllvgqqtg9uw8VuxLX8qz7UuSlo4hTFK7RMBee8E//wk/+lFeKHz99eGUU94/3YUkqX0MYZKWSO/ecPLJefkjp7SQpKVnCJO0VJzSQpI+HEOYpA9l4ZQWv/pVeUqLb33LKS0kaXEMYZI+tO7d4bDD4MkncwC74AL4+MfzlBa//S0MGgTduuWv48cXXa0k1Ydqrh0pqYtZeeU8pcWoUfCd7+RAFlEeKzZ9en4M8iz9ktSVeSRMUodbOKXFqqt+cLD+3LkwenQxdUlSPTGESaqKiLbHhc2YUdtaJKkeGcIkVc3AgZXbl18e5s2rbS2SVG8MYZKqZswY6NPn/W09esAbb8BWW8FjjxVTlyTVA0OYpKppbs6Lfzc15dOTTU1w6aVw3XUwc2Zeh/JXv3KSV0ldk1dHSqqq5ubKV0L+4x9w0EHwzW/CpElw8cXw0Y/WvDxJKoxHwiQVYrXVcvj65S/hz3+GjTeGG24ouipJqh1DmKTCdOsG3/423H8/9O8PI0bk+2+9VXRlklR9hjBJhdt4Y7jvPjjqKDjnHPjMZ1yDUlLnZwiTVBeWXRbOPBNuvDHPL/aZz8BZZ8GCBUVXJknVYQiTVFd22SUfBdt1V/if/8lfn3uu6KokqeMZwiTVnY98BP74Rxg7Fu6+GzbZJN+XpM7EECapLkXAN74Bf/97nl9szz3z/TffLLoySeoYhjBJdW399eGee+CEE+DCC/MEr1OmFF2VJH14hjBJda9XLzjtNLj1Vpg7Ny95dNpp8N57RVcmSUvPECapYQwdmgft77knnHQS7LgjPPNM0VVJ0tIxhElqKP36wRVX5DUop0zJg/avuKLoqiRpyRnCJDWcCPjqV2HqVPjEJ2DfffP9iy6CQYNghx22Z9AgGD++6EolqW0u4C2pYa27Ltx1F5x6KvzoR/Db30JKAMH06TBqVN6v0gLiklQ0j4RJamg9e8IPf5jXnswBrGzuXBg9upi6JGlxDGGSOoUXX6zcPmNGbeuQpPYyhEnqFAYOrNy+1lq1rUOS2ssQJqlTGDMG+vT5YHufPvDaa7WvR5IWxxAmqVNoboZx4/ISRxGJpiY44gj4z39gm208LSmp/hjCJHUazc0wbRrcdtsdTJsG55wDN90Ezz4LW2+dJ3qVpHphCJPUqQ0ZkqexiIBtt4Xbby+6IknKDGGSOr2NN86LgA8YALvsAhMmFF2RJBnCJHURAwbkI2Jbbw377QdnnFF0RZK6OkOYpC6jX788RmzvveGYY+Doo2HBgqKrktRVGcIkdSnLLptPR37723Dmmfmo2Lx5RVclqSty7UhJXU737nDWWXki1+OPz7PtX3MNrLRS0ZVJ6ko8EiapS4qA446Dyy+Hv/wlXzk5c2bRVUnqSgxhkrq05maYNAmmT8+D9h99tOiKJHUVhjBJXd6wYXDnnTB/fp5d/847i65IUldgCJMkYNNN81xi/fvDTjvBlVcWXZGkzs4QJkklgwbl8WGDB8OXvwxnn110RZI6M0OYJLWwyipwyy0wciR85zv56knnEpNUDYYwSWqld+98OvLww+H00+HAA+Gdd4quSlJnU9UQFhG7RsQTEfFURJxY4fEhEfF6REwtbd+vZj2S1F7du8N558GYMTB+PIwYAW+8UXRVkjqTqk3WGhHdgfOAnYCZwP0RcV1K6Z+tdr0rpfSFatUhSUsrAr77XVhjDfj612G77fJ0FmusUXRlkjqDah4J2wJ4KqX0dErpHWACMLKKrydJVXHQQfCnP8FTT+W5xB57rOiKJHUG1QxhawLPtLg/s9TW2tYR8VBE3BARG1axHklaarvuCnfcAW+/DZ/7HPzgB/lqym7d8tfx44uuUFKjiZRSdZ444kvALimlQ0v3DwC2SCkd2WKfFYAFKaU5ETEC+GVKab0KzzUKGAXQv3//zSdMmFCVmhvJnDlz6Nu3b9FlFM5+KLMvyqrZF889tyxHHPFpXnutFxD/v32ZZd7j2GOfYNiwF6vyukvLz0VmP5TZF2W16IuhQ4dOSSkNrvRYNUPY1sApKaVdSvdPAkgp/e8ivmcaMDil9HJb+wwePDg98MADHVxt45k8eTJDhgwpuozC2Q9l9kVZtftiwIDK60w2NcG0aVV72aXi5yKzH8rsi7Ja9EVEtBnCqnk68n5gvYhYOyJ6AfsC17UqbLWIiNLtLUr1vFLFmiTpQ3v22crtM2bUtg5Jja1qV0emlOZHxBHATUB34JKU0qMRcVjp8bHA3sDhETEfeAvYN1Xr0JwkdZCBA/OC35XaJam9qhbCAFJKk4BJrdrGtrh9LnBuNWuQpI42ZgyMGgVz576//VOfgpTy1BaStDjOmC9JS6i5GcaNy2PAIvIRsKFD4brr4KijXOZIUvtU9UiYJHVWzc15WyglOPpoOOssePNNuOCCPOu+JLXFECZJHSACzjgD+vaFU0/NQeyyy6Bnz6Irk1SvDGGS1EEi4Mc/zkHsxBPzmLErroBlly26Mkn1yDFhktTBTjgBzjknjxHbffcPDuCXJDCESVJVHHEEXHIJ3HprXvLojTeKrkhSvTGESVKVHHww/O53cM89sOOO8OqrRVckqZ4YwiSpivbZB66+Gh5+GIYMgRdeKLoiSfXCECZJVbbbbjBxIvz737DddvDMM0VXJKkeGMIkqQaGDYObboLnn4dtt82BTFLXZgiTpBrZZhu47TaYPTsfEXvssaIrklQkQ5gk1dDmm8Mdd8B77+UgNnVq0RVJKoohTJJqbKON4K67oHfvvObkvfcWXZGkIhjCJKkA662Xg9gqq+TxYpMnF12RpFozhElSQZqachBraoLhw+GGG4quSFItGcIkqUCrr57HiH3ykzByZJ5TTFLXYAiTpIKtumq+anLwYPjyl+Hyy4uuSFItGMIkqQ6stBLcfHO+YvLAA+GCC4quSFK1GcIkqU707Ztn1h8xAg47DM48s+iKJFWTIUyS6kjv3nlc2N57w9FH569NTdCtGwwaBOPHF12hpI7So+gCJEnv16sX/P73ebHvq64qt0+fDqNG5dvNzcXUJqnjeCRMkupQjx45dLU2dy6MHl37eiR1PEOYJNWpZ56p3D5jRm3rkFQdhjBJqlMDB1ZuHzCgtnVIqg5DmCTVqTFjoE+fD7Y3NeUFwCU1NkOYJNWp5mYYNy6Hroj8da+98lJHBx1kEJMaXbuujoyI5YC3UkoLIuLjwPrADSmld6tanSR1cc3NH7wScswY+N73cgi77LI8iF9S42nvj+6dwLYR0Q+4FXgA2AfwImlJqrHRo3PwOvFEmD8/zx3Ws2fRVUlaUu0NYZFSmhsRhwDnpJR+FhEPVrMwSVLbTjgBuneH446DBQvyvGIGMamxtHdMWETE1uQjXxNLbR4Al6QCHXtsXtroqqvywt/vvFN0RZKWRHtD2FHAScA1KaVHI2Id4PbqlSVJao+jjoKzz4Y//jEvcTRvXtEVSWqvdh3NSindAdwBEBHdgJdTSt+uZmGSpPY58sh8avJb38pXT151FSy7bNFVSVqcdh0Ji4jfRcQKpask/wk8ERHHVbc0SVJ7ffObcMEFMGkS7LknvPVW0RVJWpz2no7cIKX0BrAHMAkYCBxQtaokSUts1Ci46CK46SYYOTKvMympfrU3hPWMiJ7kEHZtaX6wVL2yJElL45BD4JJL4JZbYLfd4O23nZNbqlftvcLxAmAa8BBwZ0Q0AW9UqyhJ0tI76KA8Ruygg+DVVzdmm22gb9+iq5LUWrv+i5RSOjultGZKaUTKpgNDq1ybJGkpHXAA/Pa38PDDKzFiBMyeXXRFklpr78D8FSPijIh4oLT9AliuyrVJkj6Er3wFRo/+J3/9KwwfDm94/kKqK+0dLHAJMBv4cml7A/h1tYqSJHWMHXZ4iQkT4G9/g112gddfL7oiSQu1d0zYuimlL7a4/8OImFqNgiRJHWvvvfMYsS9/GXbeOV89udJKRVclqb1Hwt6KiG0W3omIzwHOQiNJDWLPPfMkrg8+CMOGwauvFl2RpPaGsDnpOi4AABpASURBVMOA8yJiWkRMA84FvlG1qiRJHW733eHqq+Ef/8hB7JVXiq5I6trae3XkQymlTwGbAJuklD4N7FDVyiRJHe4LX8jrTP7zn7DjjvDyy0VXJHVdSzSLX0rpjdLM+QBHV6EeSVKVDR8O110HTzwBO+wAL75YdEVS1/RhplKODqtCklRTO+8Mf/oTPPUUDB0KL7xQdEVS1/NhQpjLFklSAxs2DCZOhGnTYMgQmDWr6IqkrmWRISwiZkfEGxW22cAaNapRklQlQ4fCpEnwzDOw2Waw1lrQrRsMGgTjxxddndS5LTKEpZSWTymtUGFbPqW02DnGImLXiHgiIp6KiBMXsd9nIuK9iNh7ad6EJGnpbb89HH00PP88PPsspATTp8OoUQYxqZo+zOnIRYqI7sB5wHBgA2C/iNigjf1+CtxUrVokSYt22WUfbJs7F0aPrn0tUldRtRAGbAE8lVJ6OqX0DjABGFlhvyOBqwCvz5GkgsyYsWTtkj68aoawNYFnWtyfWWr7/yJiTWBPYGwV65AkLcbAgZXb11yzcrukD6+9a0cujUpTWLS+ovIs4ISU0nsRbc94ERGjgFEA/fv3Z/LkyR1VY8OaM2eO/YD90JJ9UWZflLW3L/bf/6P8/OefYN687i1aE2+/PY8//nEKK630btVqrAU/E2X2RVnhfZFSqsoGbA3c1OL+ScBJrfb5DzCttM0hn5LcY1HPu/nmmyeldPvttxddQl2wH8rsizL7omxJ+uLyy1NqakopIn896aSUll02pU02Senll6tVYW34mSizL8pq0RfAA6mNTFPNI2H3A+tFxNrAs8C+wFdaBcC1F96OiEuB61NKf6xiTZKkNjQ3562lIUPympM77QS33gr9+hVSmtQpVW1MWEppPnAE+arHx4A/pJQejYjDIuKwar2uJKnj7LxzXvT70Udhl13g9deLrkjqPKp5JIyU0iRgUqu2ioPwU0oHVbMWSdLSGTECrrwSvvhF2HVXuOkmWGGFoquSGl81r46UJHUSu+0GV1wB99+fQ9mcOUVXJDU+Q5gkqV323BN+/3u49174/OfhzTeLrkhqbIYwSVK7felL8Nvfwt135wH7c+cWXZHUuAxhkqQlst9+8JvfwO23wx57wNtvF12R1JgMYZKkJbb//nDxxfDnP+fTlPPmFV2R1HgMYZKkpXLwwTBuHNx4I+y9N7zzTtEVSY3FECZJWmpf/zqcfz5cfz3suy+829irG0k1ZQiTJH0ohx8OZ58N11wDX/kKzJ9fdEVSY6jqZK2SpK7hyCNz+Dr6aOjRI19B2cO/MNIi+SMiSeoQ//M/+XTkCSfkAHbppdC9e9FVSfXLECZJ6jDHH5+D2Pe+l4PYxRdDNwe+SBUZwiRJHWr06BzEfvjDHMQuuMAgJlViCJMkdbgf/CCPERszBnr2hPPOg4iiq5LqiyFMktThIuDHP85HxH72s3xE7Je/NIhJLRnCJElVEQGnnZaD2Jln5iNiP/+5QUxayBAmSaqaCPjFL/KpyTPOyEfETjvNICaBIUySVGUR+VTk/Pn51GTPnvlUpUFMXZ3Xq0iSqi4Czj0XDj00D9bfe28YNChfNTloEIwfX3SFUu15JEySVBPduuXpKp54Aq6+utw+fTqMGpVvNzcXU5tUBI+ESZJqplu3HLpamzs3zy8mdSWGMElSTT3zTOX2GTNqW4dUNEOYJKmmBg6s3D5gQG3rkIpmCJMk1dSYMdCnzwfb11wzzykmdRWGMElSTTU3w7hx0NSUr5psaoJ99oF77oEvfhHefrvoCqXaMIRJkmquuRmmTYMFC/LXCRPg/PPh+uthxAiYPbvoCqXqM4RJkurC4YfDZZfBnXfCTjvBq68WXZFUXYYwSVLd2H9/uOoqePBBGDIEnn++6Iqk6jGESZLqysiRMHEi/PvfsO22lecVkzoDQ5gkqe4MGwa33AIvv5yD2JNPFl2R1PEMYZKkurT11nD77flqyW23hYceKroiqWMZwiRJdWvTTeGuu6BXrzxG7J57iq5I6jiGMElSXfvEJ+Duu2HVVfNVk7feWnRFUscwhEmS6l5TUz4itvbaeR6x664ruiLpwzOESZIawmqrwR135FOUe+0Fv/td0RVJH44hTJLUMFZeOV81ud12eU6xsWOLrkhaeoYwSVJDWX75PI/Y5z+fZ9n/2c+KrkhaOoYwSVLD6d0brr4a9t0XTjgBRo+GlIquSloyPYouQJKkpdGzJ1x+eT4y9pOfwBtvwC9/Cd08vKAGYQiTJDWs7t3hggtgxRXh5z+H2bPhoough3/d1AD8mEqSGlpEHhe24opw8sk5iP3ud7DMMkVXJi2aB20lSQ0vAr73PTjrrDxWbPfd4c03i65KWjRDmCSp0/jOd+CSS/I0FrvsAq+/XnRFUtsMYZKkTuXgg+GKK+C+++BTn4IBA2CHHbZn0CAYP77o6qQyx4RJkjqdvffOIez00xe2BNOnw6hR+V5zc1GVSWUeCZMkdUp/+MMH2+bOzXOKSfXAECZJ6pRmzFiydqnWDGGSpE5p4MDK7R/5SG3rkNpS1RAWEbtGxBMR8VREnFjh8ZER8XBETI2IByJim2rWI0nqOsaMgT593t8WAS+/DBMmFFOT1FLVQlhEdAfOA4YDGwD7RcQGrXa7FfhUSmlT4GvARdWqR5LUtTQ3w7hx0NQEEYmmpjy7/jbbwH77wdlnF12hurpqHgnbAngqpfR0SukdYAIwsuUOKaU5Kf3/JVeXA1x+VZLUYZqbYdo0uO22O5g2Db7+dbjpJthzzzynmAt/q0iRqvTpi4i9gV1TSoeW7h8AbJlSOqLVfnsC/wt8FPh8SumeCs81ChgF0L9//80neByZOXPm0Ldv36LLKJz9UGZflNkXZfZF1rof3nsPzjrr41x//RqMGDGLo49+ku7du0Ya8zNRVou+GDp06JSU0uBKj1VznrCo0PaBT3hK6RrgmojYDvgxMKzCPuOAcQCDBw9OQ4YM6dhKG9DkyZOxH+yHluyLMvuizL7IKvXDDjvAD34AP/7x6vTosToTJkDv3sXUV0t+JsqK7otqno6cCQxocX8t4Lm2dk4p3QmsGxGrVrEmSZKAPEj/Rz+C886DP/0Jdt4ZXnut6KrUlVQzhN0PrBcRa0dEL2Bf4LqWO0TExyIiSrc3A3oBr1SxJkmS3ueb38wTu953H2y3HTz7bNEVqauoWghLKc0HjgBuAh4D/pBSejQiDouIw0q7fRF4JCKmkq+k3CdVa5CaJElt2HtvuOEGmD4dPvtZePzxoitSV1DVtSNTSpOASa3axra4/VPgp9WsQZKk9thhB7jjDhg+PE9jMXEibLll0VWpM3PGfEmSSj79afjLX2DFFXMou/HGoitSZ2YIkySphXXXhb/+FT7xCdhtN7j88qIrUmdlCJMkqZX+/WHy5DxQ/4AD4Iwziq5InZEhTJKkClZYASZNyoP2jzkGjj/e2fXVsQxhkiS1YZll8mLf3/oWnH46HHwwvPtu0VWps6jq1ZGSJDW67t3hnHNgtdXg5JPhpZfyvGLLLVd0ZWp0HgmTJGkxIuB734Nx4/IVk8OGwStOLa4PyRAmSVI7ff3rcOWV8OCDeS6xGTOKrkiNzBAmSdIS2HNPuPlmmDULPvc5ePTRoitSozKESZK0hLbbDu68E+bPh223zfOKSUvKECZJ0lLYZJMcvlZdNY8RO/ZYGDQIunXLX8ePL7pC1TuvjpQkaSmtvXZe5mjLLeEXvyi3T58Oo0bl283NxdSm+ueRMEmSPoSPfCSflmxt7lwYPbr29ahxGMIkSfqQZs6s3O7Vk1oUQ5gkSR/SwIGV21de2aWO1DZDmCRJH9KYMdCnz/vbunXLE7rutVeeZV9qzRAmSdKH1NycZ9Nvasqz6zc1waWX5vUmJ02CjTaC668vukrVG0OYJEkdoLkZpk2DBQvy1wMOyNNWPPBAXndyt93gG9+AOXOKrlT1whAmSVIVbbwx3HcfHH88XHghbLop3HNP0VWpHhjCJEmqsmWWgZ/+FCZPztNZbLMNnHwyvPtu0ZWpSIYwSZJqZLvt4OGH4cAD4dRTYaut4LHHiq5KRTGESZJUQyusAL/+NVx9dZ5HbLPN4Oyz81gydS2GMEmSCrDnnvCPf8COO8J3vgO77NL2pK/qnAxhkiQVZLXV4E9/grFj82LgG28MEyYUXZVqxRAmSVKBIvLUFVOnwvrrw3775e2114quTNVmCJMkqQ6stx7cdRf8+Mdw5ZX5qNgttxRdlarJECZJUp3o0QO+9708j1jfvrDTTnm82FtvFV2ZqsEQJklSnRk8GP7+dzjyyHzl5Oabw5QpRVeljmYIkySpDvXpkwPYTTfB66/nOcXGjMmTvapzMIRJklTHdt45T2XxxS/mU5XbbQdnnAGDBkG3bvnr+PFFV6ml0aPoAiRJ0qKtvHKeumLkSDjkkPevPTl9OowalW83NxdTn5aOR8IkSWoQ++2XA1lrc+fC6NG1r0cfjiFMkqQG8txzldtnzICUaluLPhxDmCRJDWTgwMrtKcHWW8ONNxrGGoUhTJKkBjJmTL5ysqU+feBrX4NZs2D48Hwl5Q03GMbqnSFMkqQG0twM48ZBU1Ne8qipKd+/+GL417/y7RdegBEjYMstYdIkw1i9MoRJktRgmpth2jRYsCB/XXhVZK9e8PWvw5NPwoUXwksvwec/D1tsARMnGsbqjSFMkqROplcvOPTQHMYuughefhm+8IUcxu65ZxXDWJ0whEmS1En17JnnFVsYxl55Bb773Y35zGfgT3/yyFjRDGGSJHVyC8PYE0/Accc9zmuvwe675zUqDWPFMYRJktRF9OwJI0Y8z+OPwyWXwH//Ww5j111nGKs1Q5gkSV1Mz55w8MHw+OPw61/nBcJHjoTNN4drrzWM1YohTJKkLqpnTzjooBzGLr0U3ngD9tgDNtsM/vjHvDC4C4VXjyFMkqQurkcP+OpXcxj7zW9gzhzYc0844IC8QHhK5YXCqxXEumLg61F0AZIkqT706AEHHghf+Qqstlq+mrKluXPzPGTXXw/LLNNx26RJcPzx8NZb+XUWBj4oz4HWGRnCJEnS+/ToAa++Wvmxt96CBx6AefM+uHXkWLK5c2H0aEOYJEnqYgYOzEekWmtqyssjtZYSzJ9fOZwtbjv44Mo1zJjRse+p3lQ1hEXErsAvge7ARSml01o93gycULo7Bzg8pfRQNWuSJEmLN2ZMPiU4d265rU+f3F5JRB7o37Mn9O27ZK91yimVA1///kv2PI2magPzI6I7cB4wHNgA2C8iNmi123+A7VNKmwA/BsZVqx5JktR+bS0UXo3Tg2PG5IDXUkSex+wvf+n416sX1bw6cgvgqZTS0ymld4AJwMiWO6SU/ppSeq10915grSrWI0mSlkBbC4VX43VaB76zzsqnRHfeGf785+q8btEiVWlGtojYG9g1pXRo6f4BwJYppSPa2P9YYP2F+7d6bBQwCqB///6bT5gwoSo1N5I5c+bQd0mP93ZC9kOZfVFmX5TZF5n9UNZIffHqqz057rhP8cwzffj+9//JNtu83KHPX4u+GDp06JSU0uBKj1VzTFhUaKuY+CJiKHAIsE2lx1NK4yidqhw8eHAaMmRIB5XYuCZPnoz9YD+0ZF+U2Rdl9kVmP5Q1Wl8MHQrDh8Mpp2zEpZfC/vt33HMX3RfVPB05ExjQ4v5awHOtd4qITYCLgJEppVdaPy5Jkrqufv3y6cjttstzmI0dW3RFHaeaIex+YL2IWDsiegH7Ate13CEiBgJXAweklJ6sYi2SJKlBLb88TJwII0bA4YfD6acXXVHHqNrpyJTS/Ig4AriJPEXFJSmlRyPisNLjY4HvA6sA50cEwPy2zptKkqSuq3dvuOaavJTS8cfndS5/9KM8kL9RVXWesJTSJGBSq7axLW4fCnxgIL4kSVJrPXvmNSX79oVTT81B7Mwz83qTjcgZ8yVJUsPo3h0uvDCfojzrrLzY+Lhxub3RGMIkSVJDiYAzzoAVV4Qf/hBmz4bLL4devYqubMkYwiRJUsOJyMsdLb88HHssvPkmXHllHjvWKBr0LKokSRIccwxccAHccEOeT2z27KIraj9DmCRJamijRuUB+3ffDcOGwauvFl1R+xjCJElSw9tvP7j6apg6FbbfHp5/vuiKFs8QJkmSOoXdd8+Tuj79dJ5hf8aMoitaNEOYJEnqNIYNy8scvfgibLMNPFnH6/EYwiRJUqfy2c/C5Mnw9tv5iNjDDxddUWWGMEmS1OlsuinceSf06AFDhsDf/lZ0RR9kCJMkSZ3S+uvnKyb79cunKSdPLrqi9zOESZKkTmvQILjrLhg4MM8jNnFi0RWVGcIkSVKntsYacMcdsOGGsMcecOSROZztsMP2DBqU5xgrgssWSZKkTm/VVeHWW2GLLeDccxe2BtOn58leAZqba1uTR8IkSVKXsOKK8NZbH2yfOxdGj659PYYwSZLUZcycWbm9iIldDWGSJKnLGDhwydqryRAmSZK6jDFjoE+f97f16ZPba80QJkmSuozmZhg3DpqaICLR1JTv13pQPhjCJElSF9PcDNOmwW233cG0acUEMDCESZIkFcIQJkmSVABDmCRJUgEMYZIkSQUwhEmSJBXAECZJklQAQ5gkSVIBDGGSJEkFMIRJkiQVwBAmSZJUgEgpFV3DEomIl4DpRddRB1YFXi66iDpgP5TZF2X2RZl9kdkPZfZFWS36oiml9JFKDzRcCFMWEQ+klAYXXUfR7Icy+6LMviizLzL7ocy+KCu6LzwdKUmSVABDmCRJUgEMYY1rXNEF1An7ocy+KLMvyuyLzH4osy/KCu0Lx4RJkiQVwCNhkiRJBTCE1amIGBARt0fEYxHxaER8p8I+QyLi9YiYWtq+X0SttRAR0yLiH6X3+UCFxyMizo6IpyLi4YjYrIg6qy0iPtHi33tqRLwREUe12qfTfi4i4pKIeDEiHmnRtnJE/Dki/lX62q+N7901Ip4ofUZOrF3V1dFGX5weEY+XfgauiYiV2vjeRf48NZI2+uGUiHi2xc/AiDa+tyt8Jq5o0Q/TImJqG9/bmT4TFf9+1uXvipSSWx1uwOrAZqXbywNPAhu02mcIcH3RtdaoP6YBqy7i8RHADUAAWwF/K7rmGvRJd+B58hw0XeJzAWwHbAY80qLtZ8CJpdsnAj9to6/+DawD9AIeav3z1GhbG32xM9CjdPunlfqi9Ngif54aaWujH04Bjl3M93WJz0Srx38BfL8LfCYq/v2sx98VHgmrUymlWSmlv5duzwYeA9Ystqq6NhK4LGX3AitFxOpFF1VlOwL/Til1mcmLU0p3Aq+2ah4J/KZ0+zfAHhW+dQvgqZTS0ymld4AJpe9rWJX6IqV0c0ppfunuvcBaNS+sxtr4TLRHl/hMLBQRAXwZ+H1NiyrAIv5+1t3vCkNYA4iIQcCngb9VeHjriHgoIm6IiA1rWlhtJeDmiJgSEaMqPL4m8EyL+zPp/KF1X9r+hdpVPhcA/VNKsyD/8gU+WmGfrvj5+Br56HAli/t56gyOKJ2WvaSN005d7TOxLfBCSulfbTzeKT8Trf5+1t3vCkNYnYuIvsBVwFEppTdaPfx38qmoTwHnAH+sdX019LmU0mbAcOBbEbFdq8ejwvd02kt/I6IXsDvwfxUe7kqfi/bqap+P0cB8YHwbuyzu56nR/QpYF9gUmEU+Dddal/pMAPux6KNgne4zsZi/n21+W4W2qn0uDGF1LCJ6kj9A41NKV7d+PKX0RkppTun2JKBnRKxa4zJrIqX0XOnri8A15EPGLc0EBrS4vxbwXG2qK8Rw4O8ppRdaP9CVPhclLyw89Vz6+mKFfbrM5yMivgp8AWhOpUEurbXj56mhpZReSCm9l1JaAFxI5ffXlT4TPYC9gCva2qezfSba+PtZd78rDGF1qnT+/mLgsZTSGW3ss1ppPyJiC/K/5yu1q7I2ImK5iFh+4W3y4ONHWu12HXBg6SrJrYDXFx527qTa/F9tV/lctHAd8NXS7a8C11bY535gvYhYu3QUcd/S93UqEbErcAKwe0ppbhv7tOfnqaG1Gg+6J5XfX5f4TJQMAx5PKc2s9GBn+0ws4u9n/f2uKPoqBrc2r+7YhnwI9GFgamkbARwGHFba5wjgUfLVG/cCny267ir1xTql9/hQ6f2OLrW37IsAziNf1fIPYHDRdVexP/qQQ9WKLdq6xOeCHDxnAe+S/8d6CLAKcCvwr9LXlUv7rgFMavG9I8hXSf174Weokbc2+uIp8niWhb8zxrbui7Z+nhp1a6Mfflv6PfAw+Q/o6l31M1Fqv3Th74cW+3bmz0Rbfz/r7neFM+ZLkiQVwNORkiRJBTCESZIkFcAQJkmSVABDmCRJUgEMYZIkSQUwhEnqVCLivYiY2mI7sQOfe1BENOz8SZLqS4+iC5CkDvZWSmnToouQpMXxSJikLiEipkXETyPivtL2sVJ7U0TcWlrs+daIGFhq7x8R15QWQn8oIj5beqruEXFhRDwaETdHRO/C3pSkhmYIk9TZ9G51OnKfFo+9kVLaAjgXOKvUdi5wWUppE/KC12eX2s8G7kh5IfTNyDOJA6wHnJdS2hD4L/DFKr8fSZ2UM+ZL6lQiYk5KqW+F9mnADimlp0uL+z6fUlolIl4mL2vzbql9Vkpp1Yh4CVgrpTSvxXMMAv6cUlqvdP8EoGdK6dTqvzNJnY1HwiR1JamN223tU8m8Frffw7G1kpaSIUxSV7JPi6/3lG7/Fdi3dLsZuLt0+1bgcICI6B4RK9SqSEldg/+Dk9TZ9I6IqS3u35hSWjhNxTIR8Tfyf0D3K7V9G7gkIo4DXgIOLrV/BxgXEYeQj3gdDsyqevWSugzHhEnqEkpjwganlF4uuhZJAk9HSpIkFcIjYZIkSQXwSJgkSVIBDGGSJEkFMIRJkiQVwBAmSZJUAEOYJElSAQxhkiRJBfh/Kou0roVqc9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Define the model\n",
    "# 30 input features\n",
    "model = BreastCancerClassifier()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# List to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Append the average loss to the loss_values list\n",
    "    loss_values.append(avg_loss)\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to PyTorch tensors (if not already)\n",
    "x_test = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "y_test = torch.tensor(Y_test.values.astype(np.float32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAGDCAYAAACm1SA/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhlVXnv8e+vu0GaeRCQiATRBsQBMEhwQgQhAiokiuCUBo2tUTA4xJCYB4Tcm2jidYgaFTWKMlyFQEBwgLQSxQgyBxCuGFQQWoZmnunmvX+cXVI03VWnu3rX7l31/fDs55w9rbVOcbreetdee+1UFZIkaWwzum6AJEl9YMCUJGkIBkxJkoZgwJQkaQgGTEmShmDAlCRpCAZMTUtJZif5VpK7kpw8gXLelOTsldm2LiT5TpK5XbdDWpUZMLVKS/LGJBcluTfJguYX+0tWQtGvAzYFNqqqA1a0kKo6oar2WgnteZwkuyWpJKcusX37Zvu5Q5bz4STHj3dcVe1dVcetYHOlacGAqVVWkvcBnwT+nkFw2wL4F2C/lVD87wM/r6pFK6GsttwKvCjJRqO2zQV+vrIqyIC/B6Qh+A9Fq6Qk6wHHAO+uqlOr6r6qeqSqvlVVf9kc86Qkn0xyU7N8MsmTmn27JflNkvcnuaXJTg9p9h0NHAkc2GSub1syE0uyZZPJzWrWD05yXZJ7kvwyyZtGbT9v1HkvSnJh09V7YZIXjdp3bpK/S/Ljppyzkzx5jB/Dw8C/Awc1588EXg+csMTP6lNJbkhyd5KLk7y02f5K4G9Gfc7LR7Xjfyf5MXA/sFWz7c+a/Z9Lcsqo8j+aZH6SDP0/UJqCDJhaVb0QWAM4bYxjPgTsAuwAbA/sDPztqP1PAdYDngq8Dfhskg2q6igGWes3qmrtqvryWA1Jshbwz8DeVbUO8CLgsqUctyFwVnPsRsDHgbOWyBDfCBwCbAKsDnxgrLqBrwF/2rz/I+Aq4KYljrmQwc9gQ+BE4OQka1TVd5f4nNuPOuctwDxgHeDXS5T3fuB5zR8DL2Xws5tbzqOpac6AqVXVRsBt43SZvgk4pqpuqapbgaMZBIIRjzT7H6mqbwP3AtusYHseBZ6TZHZVLaiqq5ZyzL7AtVX19apaVFUnAdcArx51zFeq6udV9QDwTQaBbpmq6r+ADZNswyBwfm0pxxxfVQubOv8P8CTG/5xfraqrmnMeWaK8+4E3Mwj4xwOHVdVvxilPmvIMmFpVLQSePNIlugy/x+Ozo183235XxhIB935g7eVtSFXdBxwIvBNYkOSsJNsO0Z6RNj111PpvV6A9XwcOBV7OUjLuptv56qYb+E4GWfVYXb0AN4y1s6p+ClwHhEFgl6Y9A6ZWVT8BHgT2H+OYmxgM3hmxBU/srhzWfcCao9afMnpnVX2vqvYENmOQNX5xiPaMtOnGFWzTiK8D7wK+3WR/v9N0mf4Vg2ubG1TV+sBdDAIdwLK6UcfsXk3ybgaZ6k3AB1e86dLUYcDUKqmq7mIwMOezSfZPsmaS1ZLsneQfm8NOAv42ycbN4JkjGXQhrojLgF2TbNEMOPrrkR1JNk3ymuZa5kMMunYXL6WMbwNbN7fCzEpyILAdcOYKtgmAqvol8DIG12yXtA6wiMGI2llJjgTWHbX/ZmDL5RkJm2Rr4H8x6JZ9C/DBJGN2HUvTgQFTq6yq+jjwPgYDeW5l0I14KIORozD4pX4R8N/AFcAlzbYVqesc4BtNWRfz+CA3g8FAmJuA2xkEr3ctpYyFwKuaYxcyyMxeVVW3rUiblij7vKpaWvb8PeA7DG41+TWDrHx0d+vIpAwLk1wyXj1NF/jxwEer6vKqupbBSNuvj4xAlqarOPBNkqTxmWFKkjQEA6YkSUMwYEqSNAQDpiRJQzBgSpI0hLFmUenU7B0Pdfiueu+OCz/TdROklWKNWbQ2+f5Ef98/cOlnJuXBAKtswJQkTRM9ecJcP1opSVLHzDAlSd3qyaNWDZiSpG71pEvWgClJ6lZPMsx+hHVJkjpmhilJ6pZdspIkDaEnXbIGTElSt8wwJUkaQk8yzH6EdUmSOmaGKUnqll2ykiQNoSddsgZMSVK3zDAlSRpCTzLMfoR1SZI6ZoYpSeqWXbKSJA3BgClJ0hBmeA1TkqQpwwxTktQtu2QlSRpCT24rMWBKkrplhilJ0hB6kmH2I6xLktQxM0xJUrfskpUkaQg96ZI1YEqSumWGKUnSEHqSYfYjrEuS1DEzTElSt+ySlSRpCD3pkjVgSpK61ZMMsx+tlCSpY2aYkqRu9STDNGBKkrrlNUxJkoZghilJ0hB6kmH2I6xLktQxA6YkqVuZMbFlmCqS9ZOckuSaJFcneWGSDZOck+Ta5nWDscowYEqSupVMbBnOp4DvVtW2wPbA1cARwPyqmgPMb9aXyYApSepUkgktQ5S/LrAr8GWAqnq4qu4E9gOOaw47Dth/rHIMmJKkTk00YCaZl+SiUcu8JarYCrgV+EqSS5N8KclawKZVtQCged1krHY6SlaS1GtVdSxw7BiHzAKeDxxWVRck+RTjdL8ujRmmJKlbmeAyvt8Av6mqC5r1UxgE0JuTbAbQvN4yViEGTElSp9q+hllVvwVuSLJNs2kP4GfAGcDcZttc4PSxyrFLVpLUqWGC3kpwGHBCktWB64BDGCSN30zyNuB64ICxCjBgSpKmvKq6DNhpKbv2GLYMA6YkqVOTlGFOmAFTktQpA6YkScPoR7w0YEqSutWXDNPbSiRJGoIZpiSpU33JMA2YkqROGTAlSRqCAVOSpGH0I1466EeSpGGYYUqSOmWXrCRJQzBgSpI0hL4ETK9hSpI0BDNMSVK3+pFgGjAlSd3qS5esAVOS1CkDZiPJTGDT0XVV1fVt1ytJ6gcDJpDkMOAo4Gbg0WZzAc9rs15Jkla2tjPMvwC2qaqFLdcjSeopM8yBG4C7Wq5DktRn/YiXrQfM64Bzk5wFPDSysao+3nK9kqSeMMMcuL5ZVm8WSZIex4AJVNXRbZYvSdJkaXuU7LcYjIod7S7gIuALVfVgm/VLklZ9fckw255L9jrgXuCLzXI3g1tMtm7WJUnTXSa4TJK2r2HuWFW7jlr/VpIfVtWuSa5quW5JUg+YYQ5snGSLkZXm/ZOb1YdbrluSpJWm7Qzz/cB5Sf6HQeL8dOBdSdYCjmu5bi1hvbVn87mj3sh2z9iMKnjn0Sdw/4MP8+kPHcRas5/Er29ayCEfOo577vPSsvrhtwsW8KG//iALF95GMoPXHfB63vSWuV03S8upLxlm26Nkv51kDrAtg4B5zaiBPp9ss2490cc++DrO/q+f8ca//DKrzZrJmmuszlmfP5QjPnEa5138C/50v11479w9OOZfzuq6qdJQZs6ayQc+eATP2u7Z3HffvRx0wGvZ5YUv5hnPfGbXTdNy6EvAbKVLNsnuzeufAPsCzwC2AvZptmmSrbPWGrzk+c/gq6f9BIBHFi3mrnsfYM7vb8J5F/8CgO+ffw3777FDl82UlsvGG2/Cs7Z7NgBrrbU2W221FbfccnPHrdLySjKhZbK0lWG+DPg+8Oql7Cvg1Jbq1TI8/akbcdsd93Ls0W/muVs/lUuvvoEP/OMp/Ox/FvCq3Z7LmedewZ/s+Xw233SDrpsqrZAbb/wN11x9Nc993vZdN0XLqx8JZjsZZlUd1bwespTlrcs6L8m8JBcluWjRbQ6iXZlmzZrJDts+jS+e/CNe+IaPcv8DD/GBt+7JOz58Au94/a78+IQPsvaaT+LhRxZ33VRpud1/3328//D38JdH/A1rr712183RFNX2xAVPAl4LbMnjn4d5zNKOr6pjgWMBZu946JITHmgCbrz5Dm685U4uvPLXAJz2H5fx/kP25Jh/OYtXv+uzADxzi03Y+6XP7rKZ0nJ75JFHeN/h72GffV/NK/bcq+vmaAVM62uYo5wO7AcsAu4btWiS3bzwHn7z2zuY8/ubALDbzttwzXW/ZeMNBn+NJ+GIt/8RXzzlvC6bKS2XquLDR36Irbbaij89+JCum6MVNN2vYY7YvKpe2XIdGtL7PnoyX/n7g1l91kx+deNtzDvqeN70qj/kHQcO5pY4/fuX8bXTz++4ldLwLr3kYs4843TmbL01r/+T/QA47PD38dJdX9Zxy7Q8epJgkqr2ej6THAt8uqquWN5z7ZLVVHDHhZ/pugnSSrHGrPaG5jzzA9+Z0O/7X3xs70kJuW1nmC8BDk7ySwbPwwxQVfW8luuVJPVEX65hth0w9265fElSz/UkXrY76Keqfg08Ddi9eX9/23VKkvrFQT9AkqOAnYBtgK8AqwHHAy9us15JUn9MRsxL8ivgHmAxsKiqdkqyIfANBrc+/gp4fVXdsawy2s72/hh4Dc2tJFV1E7BOy3VKkrQ0L6+qHapqp2b9CGB+Vc0B5jfry9R2wHy4BsNwC6B5SokkSb8zY0YmtEzAfjz25KzjgP3HbOdEahrCN5N8AVg/yduB/wC+2HKdkqQeSSa6PDatarPMW0o1BZyd5OJR+zetqgUAzesmY7Wz7cd7fSzJnsDdDK5jHllV57RZpySpXyY6cGf0tKpjeHFV3ZRkE+CcJNcsbz1t31ZCEyDPSfJkYGHb9UmS+mUyBv00Y2ioqluSnAbsDNycZLOqWpBkM+CWscpo63mYuyQ5N8mpSXZMciVwZdM4p8qTJE2aJGslWWfkPbAXg5h0BjC3OWwug/nPl6mtDPMzwN8A6zF4LubeVXV+km2Bk4DvtlSvJKlnJuFeyk2B05p6ZgEnVtV3k1zIYKzN24DrgQPGKqStgDmrqs4GSHJMVZ0PUFXX9GUKJEnS5Gg7LlTVdcATnixeVQuBPYYtp62A+eio9w8ssc9J1SVJv9OXPKqtgLl9krsZTLY+u3lPs75GS3VKktSaVgJmVc1so1xJ0tTTl0t1rd9WIknSWHoSLw2YkqRumWFKkjSEnsRLn00pSdIwzDAlSZ2yS1aSpCH0JF4aMCVJ3TLDlCRpCD2Jlw76kSRpGGaYkqRO2SUrSdIQehIvDZiSpG71JcP0GqYkSUMww5QkdaonCaYBU5LUrb50yRowJUmdMmBKkjSEnsRLB/1IkjQMM0xJUqfskpUkaQg9iZcGTElSt8wwJUkaQk/ipYN+JEkahhmmJKlTM3qSYhowJUmd6km8NGBKkrrVl0E/XsOUJGkIZpiSpE7N6EeCacCUJHWrL12yBkxJUqd6Ei8NmJKkboV+REwH/UiSNAQzTElSpxz0I0nSEBz0I0nSEHoSLw2YkqRu9WUuWQf9SJKmvCQzk1ya5MxmfcMk5yS5tnndYLwyDJiSpE4lE1uG9BfA1aPWjwDmV9UcYH6zPiYDpiSpU0kmtAxR/ubAvsCXRm3eDziueX8csP945XgNU5LUqUm4hPlJ4IPAOqO2bVpVCwCqakGSTcYrxAxTktRrSeYluWjUMm/UvlcBt1TVxROtxwxTktSpiY6SrapjgWOXsfvFwGuS7AOsAayb5Hjg5iSbNdnlZsAt47ZzQq2UJGmCMsFlLFX111W1eVVtCRwEfL+q3gycAcxtDpsLnD5eO80wJUmd6mimn48A30zyNuB64IDxTjBgSpI6NVlzyVbVucC5zfuFwB7Lc75dspIkDcEMU5LUKSdflyRpCD2JlwZMSVK3ep9hJvk0UMvaX1XvaaVFkqRpZSo8QPqiSWuFJEmruGUGzKo6bln7JElaWXrfJTsiycbAXwHbMZhWCICq2r3FdkmSpol+hMvh7sM8gcEzxJ4OHA38CriwxTZJkqaRGcmElklr5xDHbFRVXwYeqar/rKq3Aru03C5JklYpw9xW8kjzuiDJvsBNwObtNUmSNJ305BLmUAHzfyVZD3g/8GlgXeC9rbZKkjRtTJlBP1V1ZvP2LuDl7TZHkjTd9CReDjVK9issZQKD5lqmJEkTMpkDdyZimC7ZM0e9XwP4YwbXMSVJmjaG6ZL9t9HrSU4C/qO1FkmSppWeJJgrNPn6HGCLld2QJS284NNtVyG17i3HX9J1E6SV4uSDn99a2VNm0E+Se3j8NczfMpj5R5KkCRtmQoBVwTBdsutMRkMkSdNTXzLMcQN7kvnDbJMkaSob63mYawBrAk9OsgGPzY+7LvB7k9A2SdI0MBWeh/kO4HAGwfFiHguYdwOfbbldkqRpovcBs6o+BXwqyWFV5ZBVSVIrpsw1TODRJOuPrCTZIMm7WmyTJEmrnGEC5tur6s6Rlaq6A3h7e02SJE0nMzKxZbIMM3HBjCSpqgJIMhNYvd1mSZKmi570yA4VML8HfDPJ5xlMYPBO4DuttkqSNG1MpcnX/wqYB/w5g5GylwKbtdkoSdL00ZeZfsZtZ1U9CpwPXAfsBOwBXN1yuyRJWqWMNXHB1sBBwBuAhcA3AKrKh0hLklaanvTIjtklew3wI+DVVfULgCTvnZRWSZKmjb5cwxyrS/a1DJ5M8oMkX0yyB4/N9iNJ0kqRTGyZLMsMmFV1WlUdCGwLnAu8F9g0yeeS7DVJ7ZMkaZUwzKCf+6rqhKp6FbA5cBlwROstkyRNC1Np4oLfqarbgS80iyRJE9aXa5jLFTAlSVrZehIvDZiSpG715fFefZlgQZKkTplhSpI6lZ7csWjAlCR1yi5ZSZKG0PZtJUnWSPLTJJcnuSrJ0c32DZOck+Ta5nWDMdu5cj6uJEkrJsmEliE8BOxeVdsDOwCvTLILgzkF5lfVHGA+48wxYMCUJE1pNXBvs7pasxSwH3Bcs/04YP+xyjFgSpI6NdEu2STzklw0apm3ZB1JZia5DLgFOKeqLgA2raoFAM3rJmO100E/kqROTXTigqo6Fjh2nGMWAzskWR84LclzlrceA6YkqVOTOTVeVd2Z5FzglcDNSTarqgVJNmOQfS6TXbKSpCktycZNZkmS2cArGDzz+QxgbnPYXOD0scoxw5QkdWoS7sPcDDguyUwGieI3q+rMJD8BvpnkbcD1wAFjFWLAlCR1qu0e2ar6b2DHpWxfCOwxbDkGTElSp2Y4NZ4kSePry+O9HPQjSdIQzDAlSZ3qy+TrBkxJUqcm8z7MiTBgSpI61ZN4acCUJHWrLxmmg34kSRqCGaYkqVM9STANmJKkbvWlq9OAKUnqVHqSYvYlsEuS1CkzTElSp/qRXxowJUkd68ttJQZMSVKn+hEuDZiSpI71JMF00I8kScMww5Qkdaovt5UYMCVJnepLV6cBU5LUKTNMSZKG0I9w2Z9MWJKkTplhSpI6ZZesJElD6EtXpwFTktSpvmSYfQnskiR1ygxTktSpfuSXLWeYSQ4YZpskafpKJrZMlra7ZP96yG2SpGlqBpnQMlla6ZJNsjewD/DUJP88ate6wKI26pQk9VNPxvy0dg3zJuAi4DXAxaO23wO8t6U6JUlqTSsBs6ouBy5PcmJVPdJGHZKkqSE9GfbT9ijZnZN8GPj9pq4AVVVbtVyvJKknpnuX7IgvM+iCvRhY3HJdkqQemsyBOxPRdsC8q6q+03IdkqQeM8Mc+EGSfwJOBR4a2VhVl7RcryRJK1XbAfMPm9edRm0rYPeW65Uk9YQZJlBVL2+zfElS/zlKtpFkX+DZwBoj26rqmLbrlST1w4x+xMvW55L9PHAgcBiDW0oOYHCLiSRJvdL2XLIvqqo/Be6oqqOBFwJPa7lOSVKPZIL/jVt+8rQkP0hydZKrkvxFs33DJOckubZ53WCsctoOmA80r/cn+T3gEeDpLdcpSeqRSXhaySLg/VX1LGAX4N1JtgOOAOZX1RxgfrO+TG1fwzwzyfrAPwGXMBgh+6WW65Qk9Ujbg36qagGwoHl/T5KrgacC+wG7NYcdB5wL/NWyyml7lOzfNW//LcmZwBpVdVebdUqS+mWig36SzAPmjdp0bFUdu4xjtwR2BC4ANm2CKVW1IMkmY9UzGaNkXwRsOVJXEqrqa23XK0maHprguNQAOVqStYF/Aw6vqruznDeAthowk3wdeAZwGY/NJVuAAbNDDz30EG87+M08/PDDLF68mFfsuRd//u73dN0saWgzAh951bbcfv8jfGT+/7D26jN5725PZ+O1V+fWex/m4+f+kvsedvrqvpiM+zCTrMYgWJ5QVac2m29OslmTXW4G3DJWGW1nmDsB21VVtVyPlsPqq6/OsV/+KmuuuRaPPPIIb537Jl78kl153vY7dN00aSj7PGsTbrzrQWavNhOA/Z/7FK5YcA//fsXN7P/cTdn/uZtywsU3ddxKDavtmX4ySCW/DFxdVR8ftesMYC7wkeb19LHKaXuU7JXAU1quQ8spCWuuuRYAixYtYtGiRSxv14TUlQ3XXI3nb74u839+2++2vWCL9Tj3FwsBOPcXC9l5i/W7ap5WQCa4DOHFwFuA3ZNc1iz7MAiUeya5FtizWV+mtjPMJwM/S/JTHj/5+mtarlfjWLx4MW888LXccP31HHjQG3nu87bvuknSUA7ZeXOOv/hG1miyS4D1Zs/izgcWAXDnA4tYd43Wh2doJZrR8h/sVXUey46tewxbTtvfqg8vz8GjRzp9+rOf561/Nm+cM7SiZs6cyTdO+Xfuuftu3nf4ofzi2p/zzDlbd90saUzP33xd7npwEdctfIDtnrJ2183RNNP2bSX/uZzH/26k0/0Pe91zMqyz7rrs9IKd+a8f/8iAqVXetpuszU5PW48dN1+X1WfOYPZqMznspVty1wOLWL/JMtefPYu7H1zUdVO1HPpyQajtuWTvSXL3EssNSU5LslWbdWvZbr/9du65+24AHnzwQS44/yds+XT/d2jVd+IlN/HOk6/k3adcxSf+85dcueAePv2jX3HRDXex2zM3AmC3Z27Ehdd7u3evTMJFzJWh7S7ZjwM3AScy+FgHMRgE9P+Af+WxGRY0iW679VaO/NsjeHTxYh6tYs+9XsmuL/NJbOqv0674Le972dPZfc5G3NbcVqL+6MvjvdLmHR9JLqiqP1xi2/lVtUuSy6tqmSNN7JLVVDD3xEu7boK0Upx88PNbi2oX/M9dE/p9/4fPWG9SIm7bt5U8muT1SWY0y+tH7TMgSpImY/L1laLtgPkmBve+3ALc3Lx/c5LZwKEt1y1J6oGeXMJsfZTsdcCrl7H7vDbrliT1RD8uYbYTMJN8sKr+McmnWUrXa1U5cakkCejPoJ+2Msyrm9eLWipfkqRJ1UrArKpvNa/HtVG+JGnq6MtU1m11yX6LMUbBOpesJGlET+Jla12yH2upXEnSVNOTiNlWl+xyzSErSZq+pvugHwCSzAH+AdgOWGNke1U5cakkqVfanrjgK8DngEXAy4GvAV9vuU5JUo8408/A7Kqaz2DO2l9X1YeB3VuuU5LUI870M/BgkhnAtUkOBW4ENmm5TklSn/TjEmbrGebhwJrAe4A/YDCX7NyW65QkaaVrey7ZC5u39wKHtFmXJKmfpvUo2SRnjLXfiQskSSOm9Uw/wAuBG4CTgAvoTQ+1JGmy9SVAtBUwnwLsCbwBeCNwFnBSVV3VUn2SpL7qScRsZdBPVS2uqu9W1VxgF+AXwLlJDmujPkmS2tbaoJ8kTwL2ZZBlbgn8M3BqW/VJkvppug/6OQ54DvAd4OiqurKNeiRJ/TfdB/28BbgP2Bp4Tx77aQSoqlq3pXolST3Tk3jZ2tNK2p4QQZKkSdX21HiSJI2tJymmAVOS1KlpPehHkqRhTfdBP5IkDaUn8bL1p5VIkjQlmGFKkrrVkxTTgClJ6pSDfiRJGoKDfiRJGkJP4qWDfiRJGoYZpiSpWz1JMc0wJUmdygT/G7f85F+T3JLkylHbNkxyTpJrm9cNxivHgClJ6lQysWUIXwVeucS2I4D5VTUHmN+sj8mAKUma0qrqh8DtS2zeDziueX8csP945XgNU5LUqY4uYW5aVQsAqmpBkk3GO8EMU5LUrUxsSTIvyUWjlnltNNMMU5LUqYnO9FNVxwLHLudpNyfZrMkuNwNuGe8EM0xJUqcmYdDP0pwBzG3ezwVOH+8EA6YkaUpLchLwE2CbJL9J8jbgI8CeSa4F9mzWx2SXrCSpU20P+qmqNyxj1x7LU44BU5LUKSdflyRpKP2ImAZMSVKn+pJhOuhHkqQhmGFKkjrVkwTTgClJ6lZfumQNmJKkTk10pp/J4jVMSZKGYIYpSepWPxJMA6YkqVs9iZcGTElStxz0I0nSEBz0I0nSFGKGKUnqVj8STAOmJKlbPYmXBkxJUrcc9CNJ0hAc9CNJ0hRihilJ6lRfumTNMCVJGoIZpiSpU2aYkiRNIWaYkqRO9WWUrAFTktSpvnTJGjAlSZ3qSbw0YEqSOtaTiOmgH0mShmCGKUnqlIN+JEkagoN+JEkaQk/ipQFTktSxnkRMB/1IkjQEM0xJUqcc9CNJ0hD6MugnVdV1G9SRJPOq6tiu2yFNlN9lTQavYU5v87pugLSS+F1W6wyYkiQNwYApSdIQDJjTm9d8NFX4XVbrHPQjSdIQzDAlSRqCAbPHkixOclmSy5NckuRFEyjrmCSvWJntk0YkqSRfH7U+K8mtSc4c57zdRo5J8pokR7Td1lF175Bkn8mqT6s+Jy7otweqageAJH8E/APwshUpqKqOXJkNk5ZwH/CcJLOr6gFgT+DG5Smgqs4AzmijccuwA7AT8O1JrFOrMDPMqWNd4I6RlSR/meTCJP+d5Ohm25ZJrk7yxSRXJTk7yexm31eTvK55v0+Sa5Kcl+SfR/2F/+Ek/5rk3CTXJXlPB59T/fUdYN/m/RuAk0Z2JNk5yX8lubR53WbJk5McnOQzzftnJDm/+Y4fk+TeZvtuzffzlOY7fEIymEcmyZHN8VcmOXbU9nOTfDTJT5P8PMlLk6wOHAMc2PTiHNjqT0a9YMDst9nNP+ZrgC8BfweQZC9gDrAzg7+S/yDJrs05c4DPVtWzgTuB144uMMkawBeAvavqJcDGS9S5LfBHTdlHJVmtlU+mqej/Agc137HnAReM2ncNsGtV7QgcCfz9OGV9CvhUVb0AuGmJfTsChwPbAVsBL262f6aqXlBVzwFmA68adc6sqtq5Oe+oqnq4acc3qmqHqvrGcn5WTUEGzH57oPnHvC3wSuBrzV/NezXLpcAlDILcnOacX1bVZc37i4Etlzbg9CEAAAQhSURBVChzW+C6qvpls37SEvvPqqqHquo24BZg05X5gTR1VdV/M/i+vYEndnOuB5yc5ErgE8CzxynuhcDJzfsTl9j306r6TVU9ClzGY9/xlye5IMkVwO5L1HFq87q0fxMS4DXMKaOqfpLkyQwywgD/UFVfGH1Mki2Bh0ZtWszgL+3HHTZOVUue73dIy+MM4GPAbsBGo7b/HfCDqvrj5nt67gTqeMJ3tMlq/wXYqapuSPJhYI2lnON3WstkhjlFJNkWmAksBL4HvDXJ2s2+pybZZMiirgG2an5pAXjtRivTvwLHVNUVS2xfj8cGAR08RDnn89jlhIOGOH4kON7W/Lt43RDn3AOsM8RxmiYMmP02cg3zMuAbwNyqWlxVZzPopvpJ0/10CkP+w29GML4L+G6S84Cbgbvaab6mm6ar9FNL2fWPwD8k+TGDP/zGczjwviQ/BTZjnO9oVd0JfBG4Avh34MIh6vgBsJ2DfjTCmX70BEnWrqp7m+uhnwWurapPdN0uaUSSNRlcw68kBwFvqKr9um6Xpjb76rU0b08yF1idwcChL4xzvDTZ/gD4TPNH3Z3AWztuj6YBM0xJkobgNUxJkoZgwJQkaQgGTEmShmDAlHjck1+uTHJyMwpzRcsaPS/vl5JsN8axu63IU2aS/KqZqELSJDFgSgMj0ww+B3gYeOfonUmGuTfwCarqz6rqZ2Mcshuwwo9lkzR5DJjSE/0IeGaT/f0gyYnAFUlmJvmnUU+BeQdABj6T5GdJzgJ+N6tS8ySMnZr3r8zguaWXJ5nfzKb0TuC9TXb70iQbJ/m3po4Lk7y4OXejDJ4uc2mSLzD+FIaSVjLvw5RGSTIL2Bv4brNpZ+A5VfXLJPOAu6rqBUmeBPw4ydkMno6xDfBcBpPR/4zBFHCjy92YwUwzuzZlbVhVtyf5PHBvVX2sOe5E4BNVdV6SLRhMc/gs4CjgvKo6Jsm+wLxWfxCSnsCAKQ3MbqYYhEGG+WUGXaU/HfXklr2A541cn2Qw/+kcYFfgpKpaDNyU5PtLKX8X4IcjZVXV7ctoxysYTMc2sr5uknWaOv6kOfesJHcs43xJLTFgSgMPVNUOozc0Qeu+0ZuAw6rqe0sctw8w3gwgGeIYGFwmeWEzp++SbXGWEalDXsOUhvc94M9HHpqdZOskawE/ZPBg5JlJNgNevpRzfwK8LMnTm3M3bLYv+USMs4FDR1aSjATxHwJvarbtDWyw0j6VpKEYMKXhfYnB9clLmgcdf4FBL81pwLUMnoTxOeA/lzyxqm5lcN3x1CSXM3i6DMC3gD8eGfQDvAfYqRlU9DMeG617NLBrkksYdA1f39JnlLQMziUrSdIQzDAlSRqCAVOSpCEYMCVJGoIBU5KkIRgwJUkaggFTkqQhGDAlSRqCAVOSpCH8f+FQ2XB5vuLVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.96      0.97      0.97        71\n",
      "   Malignant       0.95      0.93      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Disable gradient computation for evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get predictions\n",
    "    test_predictions = model(x_test)\n",
    "    test_predictions_binary = (test_predictions > 0.5).numpy().flatten()\n",
    "    \n",
    "# Convert test labels to numpy\n",
    "y_test_binary = y_test.flatten()\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, test_predictions_binary)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_binary, test_predictions_binary, \n",
    "                             target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "Parameters:\n",
    "1. Learning Rate\n",
    "2. Feature Dimension of the Simple AFT (hidden_dim)\n",
    "3. Number of neurons in fully connected layers - hidden1, hidden2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFTSimple(nn.Module):\n",
    "    def __init__(self, max_seqlen, dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.to_q = nn.Linear(dim, hidden_dim)\n",
    "        self.to_k = nn.Linear(dim, hidden_dim)\n",
    "        self.to_v = nn.Linear(dim, hidden_dim)\n",
    "        self.project = nn.Linear(hidden_dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, _ = x.shape\n",
    "        Q = self.to_q(x).view(B, T, self.hidden_dim)\n",
    "        K = self.to_k(x).view(B, T, self.hidden_dim)\n",
    "        V = self.to_v(x).view(B, T, self.hidden_dim)\n",
    "        \n",
    "        weights = torch.mul(torch.softmax(K, 1), V).sum(dim=1, keepdim=True)\n",
    "        Q_sig = torch.sigmoid(Q)\n",
    "        Yt = torch.mul(Q_sig, weights)\n",
    "        Yt = Yt.view(B, T, self.hidden_dim)\n",
    "        Yt = self.project(Yt)\n",
    "        return Yt\n",
    "\n",
    "    \n",
    "class BreastCancerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=30, hidden_dim=64, fc_layers=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # AFT-style layer\n",
    "        self.aft_layer = AFTSimple(max_seqlen=input_dim, dim=input_dim, hidden_dim=hidden_dim)\n",
    "\n",
    "        # Dynamically create fully connected layers\n",
    "        if fc_layers is None:\n",
    "            fc_layers = [\n",
    "                (input_dim, 64, nn.ReLU()),\n",
    "                (64, 32, nn.ReLU()),\n",
    "                (32, 1, nn.Sigmoid())\n",
    "            ]\n",
    "        layers = []\n",
    "        for in_features, out_features, activation in fc_layers:\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(activation)\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.aft_layer(x)\n",
    "        \n",
    "        \n",
    "        x = x.squeeze(1) if x.dim() > 2 else x\n",
    "        \n",
    "        return self.fc_layers(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [32, 64, 128])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    \n",
    "    # Dynamic FC layer configuration\n",
    "    fc_layers = [\n",
    "        (X_train.shape[1], trial.suggest_categorical('hidden1', [32, 64, 128]), nn.ReLU()),\n",
    "        (trial.suggest_categorical('hidden1', [32, 64, 128]), trial.suggest_categorical('hidden2', [16, 32, 64]), nn.ReLU()),\n",
    "        (trial.suggest_categorical('hidden2', [16, 32, 64]), 1, nn.Sigmoid())\n",
    "    ]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train.values.astype(np.float32), dtype = torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.astype(np.float32), dtype = torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val.values.astype(np.float32), dtype = torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values.astype(np.float32), dtype = torch.float32)\n",
    "    \n",
    "    \n",
    "    # Create model, loss, and optimizer\n",
    "    model = BreastCancerClassifier(input_dim=X_train.shape[1], hidden_dim = hidden_dim, fc_layers=fc_layers)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create the training dataset\n",
    "    training_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # Example usage with DataLoader\n",
    "    train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_preds = (val_outputs > 0.5).float()\n",
    "        accuracy = accuracy_score(y_val, val_preds.numpy())\n",
    "        auc = roc_auc_score(y_val, val_outputs.numpy())\n",
    "    \n",
    "    # Report multiple metrics\n",
    "    trial.set_user_attr('accuracy', accuracy)\n",
    "    trial.set_user_attr('auc', auc)\n",
    "    \n",
    "    return val_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "[I 2024-12-05 22:55:56,052] A new study created in memory with name: Breast Cancer Classifier Optimization\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:55:56,741] Trial 0 finished with value: 0.2203179895877838 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0011592765018907665, 'hidden1': 32, 'hidden2': 64}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:55:57,504] Trial 1 finished with value: 0.6536221504211426 and parameters: {'hidden_dim': 128, 'learning_rate': 3.296601730499456e-05, 'hidden1': 128, 'hidden2': 16}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:55:58,228] Trial 2 finished with value: 0.2947366237640381 and parameters: {'hidden_dim': 32, 'learning_rate': 0.0029833141144117283, 'hidden1': 128, 'hidden2': 32}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:55:59,122] Trial 3 finished with value: 0.5251600742340088 and parameters: {'hidden_dim': 64, 'learning_rate': 7.443086502751495e-05, 'hidden1': 64, 'hidden2': 32}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:00,101] Trial 4 finished with value: 0.3843734562397003 and parameters: {'hidden_dim': 64, 'learning_rate': 0.00940268648875011, 'hidden1': 32, 'hidden2': 16}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:01,190] Trial 5 finished with value: 0.37283632159233093 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00466835559054752, 'hidden1': 32, 'hidden2': 64}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:02,016] Trial 6 finished with value: 0.6601850986480713 and parameters: {'hidden_dim': 32, 'learning_rate': 3.764731869559988e-05, 'hidden1': 64, 'hidden2': 32}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:02,756] Trial 7 finished with value: 1.2933238744735718 and parameters: {'hidden_dim': 64, 'learning_rate': 0.00542840361768331, 'hidden1': 128, 'hidden2': 64}. Best is trial 0 with value: 0.2203179895877838.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:03,577] Trial 8 finished with value: 0.15451902151107788 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0005217791433580834, 'hidden1': 128, 'hidden2': 32}. Best is trial 8 with value: 0.15451902151107788.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:04,460] Trial 9 finished with value: 0.6494776606559753 and parameters: {'hidden_dim': 32, 'learning_rate': 2.400812935534648e-05, 'hidden1': 128, 'hidden2': 16}. Best is trial 8 with value: 0.15451902151107788.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:05,395] Trial 10 finished with value: 0.13767503201961517 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0002735740704313133, 'hidden1': 128, 'hidden2': 32}. Best is trial 10 with value: 0.13767503201961517.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:06,412] Trial 11 finished with value: 0.1488083153963089 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0003851435180706862, 'hidden1': 128, 'hidden2': 32}. Best is trial 10 with value: 0.13767503201961517.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:07,393] Trial 12 finished with value: 0.12665274739265442 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00016818651289799452, 'hidden1': 128, 'hidden2': 32}. Best is trial 12 with value: 0.12665274739265442.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:08,363] Trial 13 finished with value: 0.14118197560310364 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00012868432087705407, 'hidden1': 128, 'hidden2': 32}. Best is trial 12 with value: 0.12665274739265442.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:09,260] Trial 14 finished with value: 0.12167329341173172 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00016998152166967242, 'hidden1': 128, 'hidden2': 32}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:10,363] Trial 15 finished with value: 0.13876493275165558 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00014044875953869026, 'hidden1': 64, 'hidden2': 32}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:11,281] Trial 16 finished with value: 0.6570759415626526 and parameters: {'hidden_dim': 128, 'learning_rate': 1.2762218247326559e-05, 'hidden1': 128, 'hidden2': 32}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:12,302] Trial 17 finished with value: 0.204740509390831 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0008789027511844297, 'hidden1': 128, 'hidden2': 32}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:13,206] Trial 18 finished with value: 0.14213156700134277 and parameters: {'hidden_dim': 32, 'learning_rate': 0.00016581973559598166, 'hidden1': 64, 'hidden2': 64}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:14,133] Trial 19 finished with value: 0.5993431210517883 and parameters: {'hidden_dim': 64, 'learning_rate': 6.693042817175518e-05, 'hidden1': 32, 'hidden2': 16}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:15,064] Trial 20 finished with value: 0.2724139094352722 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0015399413730967384, 'hidden1': 128, 'hidden2': 32}. Best is trial 14 with value: 0.12167329341173172.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:15,956] Trial 21 finished with value: 0.11927372962236404 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00019838003696230546, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:16,832] Trial 22 finished with value: 0.12316881865262985 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00024309201670805598, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:17,770] Trial 23 finished with value: 0.17291569709777832 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0006203136733536467, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:18,815] Trial 24 finished with value: 0.1390395313501358 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0002680960441477158, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:19,830] Trial 25 finished with value: 0.2649896740913391 and parameters: {'hidden_dim': 128, 'learning_rate': 7.324850180606536e-05, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:20,742] Trial 26 finished with value: 0.12352514266967773 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00022600866744463914, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:21,630] Trial 27 finished with value: 0.1885862648487091 and parameters: {'hidden_dim': 128, 'learning_rate': 9.045161116384235e-05, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:22,471] Trial 28 finished with value: 0.1418330818414688 and parameters: {'hidden_dim': 32, 'learning_rate': 0.00046471734267083134, 'hidden1': 32, 'hidden2': 64}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:23,651] Trial 29 finished with value: 0.26518747210502625 and parameters: {'hidden_dim': 64, 'learning_rate': 0.0014530365520945532, 'hidden1': 64, 'hidden2': 16}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:24,569] Trial 30 finished with value: 0.6123519539833069 and parameters: {'hidden_dim': 128, 'learning_rate': 4.196039592314769e-05, 'hidden1': 32, 'hidden2': 64}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:25,408] Trial 31 finished with value: 0.13367561995983124 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00025914361813009863, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:26,312] Trial 32 finished with value: 0.19687967002391815 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0007865896920528966, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:27,193] Trial 33 finished with value: 0.12146015465259552 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0002107689500210676, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:28,043] Trial 34 finished with value: 0.1734960824251175 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0001079392528201994, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:29,008] Trial 35 finished with value: 0.12405769526958466 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00019034275528031786, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:29,859] Trial 36 finished with value: 0.5023123025894165 and parameters: {'hidden_dim': 128, 'learning_rate': 5.5699084829867106e-05, 'hidden1': 128, 'hidden2': 16}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:30,849] Trial 37 finished with value: 0.12290938943624496 and parameters: {'hidden_dim': 64, 'learning_rate': 0.00032980599807230467, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:31,756] Trial 38 finished with value: 0.3000861406326294 and parameters: {'hidden_dim': 64, 'learning_rate': 0.0020387460206665784, 'hidden1': 64, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:32,694] Trial 39 finished with value: 0.6748806238174438 and parameters: {'hidden_dim': 64, 'learning_rate': 2.3767478456228485e-05, 'hidden1': 32, 'hidden2': 64}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:33,651] Trial 40 finished with value: 0.13675329089164734 and parameters: {'hidden_dim': 64, 'learning_rate': 0.00034335188018440386, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:34,577] Trial 41 finished with value: 0.14063721895217896 and parameters: {'hidden_dim': 64, 'learning_rate': 0.00036954055322382554, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:35,478] Trial 42 finished with value: 0.341406911611557 and parameters: {'hidden_dim': 32, 'learning_rate': 0.00010478740522123268, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:36,328] Trial 43 finished with value: 0.1538095474243164 and parameters: {'hidden_dim': 64, 'learning_rate': 0.0006195713649105245, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:37,041] Trial 44 finished with value: 0.12417777627706528 and parameters: {'hidden_dim': 128, 'learning_rate': 0.00022645908106314286, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:37,758] Trial 45 finished with value: 0.13263051211833954 and parameters: {'hidden_dim': 64, 'learning_rate': 0.0004270879359161357, 'hidden1': 128, 'hidden2': 16}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:38,636] Trial 46 finished with value: 0.13152913749217987 and parameters: {'hidden_dim': 128, 'learning_rate': 0.0001447468855152188, 'hidden1': 128, 'hidden2': 32}. Best is trial 21 with value: 0.11927372962236404.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:39,448] Trial 47 finished with value: 0.11915985494852066 and parameters: {'hidden_dim': 32, 'learning_rate': 0.00030483260875429415, 'hidden1': 128, 'hidden2': 32}. Best is trial 47 with value: 0.11915985494852066.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:40,266] Trial 48 finished with value: 0.16222628951072693 and parameters: {'hidden_dim': 32, 'learning_rate': 0.0009569107129516383, 'hidden1': 64, 'hidden2': 32}. Best is trial 47 with value: 0.11915985494852066.\n",
      "<ipython-input-18-e09bc8bbdd25>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 22:56:41,468] Trial 49 finished with value: 0.12164109945297241 and parameters: {'hidden_dim': 32, 'learning_rate': 0.0003266763537989283, 'hidden1': 128, 'hidden2': 32}. Best is trial 47 with value: 0.11915985494852066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (Val Loss): 0.11915985494852066\n",
      "  Params: \n",
      "    hidden_dim: 32\n",
      "    learning_rate: 0.00030483260875429415\n",
      "    hidden1: 128\n",
      "    hidden2: 32\n",
      "\n",
      "Best Trial Metrics:\n",
      "  Accuracy: 0.9649122807017544\n",
      "  AUC: 0.9863636363636363\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), \n",
    "                        columns=X.columns, \n",
    "                        index=X.index)\n",
    "# Assign the value of 1 to Malignant, assign 0 to Benign\n",
    "Y.loc[:, 'Diagnosis'] = Y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Split the data - 60/20/20 Train Validation Test Split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', \n",
    "                             study_name='Breast Cancer Classifier Optimization')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (Val Loss): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Print additional metrics from the best trial\n",
    "print(\"\\nBest Trial Metrics:\")\n",
    "print(f\"  Accuracy: {trial.user_attrs['accuracy']}\")\n",
    "print(f\"  AUC: {trial.user_attrs['auc']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly, evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hidden_dim = study.best_trial.params['hidden_dim']\n",
    "best_learning_rate = study.best_trial.params['learning_rate'] \n",
    "\n",
    "best_fc_layers = [\n",
    "    (X_train.shape[1], study.best_trial.params['hidden1'], nn.ReLU()),\n",
    "    (study.best_trial.params['hidden1'], \n",
    "     study.best_trial.params['hidden2'], nn.ReLU()),\n",
    "    (study.best_trial.params['hidden2'], 1, nn.Sigmoid())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0.00030483260875429415\n",
      "128\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(best_hidden_dim)\n",
    "print(best_learning_rate)\n",
    "print(study.best_trial.params['hidden1'])\n",
    "print(study.best_trial.params['hidden2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the best trial's parameters\n",
    "best_params = study.best_trial.params\n",
    "best_hidden_dim = best_params['hidden_dim']\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "\n",
    "\n",
    "# Reconstruct the best FC layers configuration\n",
    "best_fc_layers = [\n",
    "    (X_train.shape[1], best_params['hidden1'], nn.ReLU()),\n",
    "    (best_params['hidden1'], \n",
    "     best_params['hidden2'], nn.ReLU()),\n",
    "    (best_params['hidden2'], 1, nn.Sigmoid())\n",
    "]\n",
    "\n",
    "# Create the model with the best hyperparameters\n",
    "best_model = BreastCancerClassifier(\n",
    "    input_dim=X_train.shape[1], \n",
    "    hidden_dim = best_hidden_dim,\n",
    "    fc_layers=best_fc_layers)\n",
    "\n",
    "# Convert train and validation data to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Create optimizer with the best learning rate\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Retrain the model with best hyperparameters\n",
    "# Batching is not implemented. \n",
    "# The whole training dataset is processed in a single pass. \n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = best_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Convert test data to tensors\n",
    "X_test_tensor = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predictions\n",
    "    test_outputs = best_model(X_test_tensor)\n",
    "    test_preds = (test_outputs > 0.5).float()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds.numpy())\n",
    "    test_auc = roc_auc_score(y_test, test_outputs.numpy())\n",
    "    \n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_preds.numpy())\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, test_preds.numpy())\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "Test Loss: 0.6581778526306152\n",
      "Test Accuracy: 0.956140350877193\n",
      "Test AUC: 0.9921388797903701\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  5]\n",
      " [ 0 43]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        71\n",
      "           1       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test AUC: {test_auc}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
