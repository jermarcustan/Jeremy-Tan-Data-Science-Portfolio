{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Mixer\n",
    "\n",
    "by Jeremy Tan, Benjamin Ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ucimlrepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "# Data Handling and Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "# Dataset Fetching\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n"
     ]
    }
   ],
   "source": [
    "# Fetch Dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), \n",
    "                        columns=X.columns, \n",
    "                        index=X.index)\n",
    "# Assign the value of 1 to Malignant, assign 0 to Benign\n",
    "Y.loc[:, 'Diagnosis'] = Y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape is (455, 30)\n",
      "X test shape is (114, 30)\n",
      "Y train shape is (455, 1)\n",
      "Y test shape is (114, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X train shape is {X_train.shape}\")\n",
    "print(f\"X test shape is {X_test.shape}\")\n",
    "print(f\"Y train shape is {Y_train.shape}\")\n",
    "print(f\"Y test shape is {Y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0            357\n",
       "1            212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Custom PyTorch Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        # Convert NumPy array to a PyTorch tensor\n",
    "        self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
    "        self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples (n)\n",
    "        return self.data_x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the m-dimensional data point at index `idx`\n",
    "        return self.data_x[idx], self.data_y[idx]\n",
    "\n",
    "# Get the numpy values from df x and y\n",
    "x_train = X_train.values.astype(np.float32)\n",
    "y_train = Y_train.values.astype(np.float32)\n",
    "\n",
    "# Create the training dataset\n",
    "training_dataset = CustomDataset(x_train, y_train)\n",
    "\n",
    "# Example usage with DataLoader\n",
    "train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: tensor([[0.1176],\n",
      "        [0.2477]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP_Mixer_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_Mixer_Block, self).__init__()\n",
    "        self.token_mixing = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        self.channel_mixing = nn.Sequential(\n",
    "            nn.Linear(30, 16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(16, 30)\n",
    "        )\n",
    "        self.layer_norm1 = nn.LayerNorm(30)\n",
    "        self.layer_norm2 = nn.LayerNorm(30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, 30]\n",
    "        # First layer norm\n",
    "        x_norm = self.layer_norm1(x)\n",
    "        \n",
    "        # Transpose for token mixing\n",
    "        x_mixed = x_norm.transpose(1, 2)  # [batch_size, 30, 1]\n",
    "        \n",
    "        # Token mixing\n",
    "        x_token_mixed = self.token_mixing(x_mixed)  # [batch_size, 30, 1]\n",
    "        \n",
    "        # Transpose back\n",
    "        x_token_mixed = x_token_mixed.transpose(1, 2)  # [batch_size, 1, 30]\n",
    "        \n",
    "        # Residual connection\n",
    "        x = x + x_token_mixed\n",
    "        \n",
    "        # Second layer norm\n",
    "        x_norm2 = self.layer_norm2(x)\n",
    "        \n",
    "        # Channel mixing\n",
    "        x_channel_mixed = self.channel_mixing(x_norm2.squeeze(1)).unsqueeze(1)\n",
    "        \n",
    "        # Final residual connection\n",
    "        x = x + x_channel_mixed\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP_Mixer(nn.Module):\n",
    "    def __init__(self, num_blocks=4):\n",
    "        super(MLP_Mixer, self).__init__()\n",
    "        self.per_path_FC = nn.Linear(30, 30)\n",
    "        self.mixer_blocks = nn.ModuleList([MLP_Mixer_Block() for _ in range(num_blocks)])\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input is [batch_size, features]\n",
    "        x = x.view(-1, 30)\n",
    "        x = self.per_path_FC(x)\n",
    "        \n",
    "        # Add token dimension\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, features]\n",
    "        \n",
    "        # Apply mixer blocks\n",
    "        for block in self.mixer_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, features, 1]\n",
    "        x = self.global_avg_pool(x)\n",
    "        \n",
    "        # Classification head\n",
    "        x = x.view(-1, 30)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test the model\n",
    "model = MLP_Mixer()\n",
    "x = torch.rand(2, 30)\n",
    "y = model(x)\n",
    "print(\"Final output:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.7065\n",
      "Epoch [2/20], Loss: 0.6362\n",
      "Epoch [3/20], Loss: 0.5708\n",
      "Epoch [4/20], Loss: 0.5228\n",
      "Epoch [5/20], Loss: 0.4624\n",
      "Epoch [6/20], Loss: 0.4077\n",
      "Epoch [7/20], Loss: 0.3720\n",
      "Epoch [8/20], Loss: 0.3329\n",
      "Epoch [9/20], Loss: 0.2930\n",
      "Epoch [10/20], Loss: 0.2571\n",
      "Epoch [11/20], Loss: 0.2392\n",
      "Epoch [12/20], Loss: 0.2280\n",
      "Epoch [13/20], Loss: 0.1932\n",
      "Epoch [14/20], Loss: 0.1928\n",
      "Epoch [15/20], Loss: 0.1663\n",
      "Epoch [16/20], Loss: 0.1681\n",
      "Epoch [17/20], Loss: 0.1674\n",
      "Epoch [18/20], Loss: 0.1361\n",
      "Epoch [19/20], Loss: 0.1283\n",
      "Epoch [20/20], Loss: 0.1283\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxUdf3H8dfnghtgUZqoyL3gWm6lImZmgqYpLebST/BqmgtpaVlaqZSihWlWWmoR7iZJlrmUuJSKS+aemrhFBoi44Y64Ad/fH9+he7ncy3pnzszc1/PxmMfMnHNmzme+zL33zfd7zvdESglJkiRVVkPRBUiSJHVFhjBJkqQCGMIkSZIKYAiTJEkqgCFMkiSpAIYwSZKkAhjCJLUrIq6LiAM6e1tVr4g4MCLuKLoOqaswhEl1JCJmtbrNi4i3Wj1vXpr3SintllK6uLO3XRoRMTgipnf2+y7hviMivhMR/y6147SIODUiVqrQ/geX/g1ntbltW4n9Syq/7kUXIKnzpJR6zX8cEVOAQ1JKf2u7XUR0TynNqWRtNeiXwK7Al4F7gY2AC4GPALt35o4W8e8xI6W0TmfuS1L1sCdM6gLm9yhFxPci4jngwoj4QET8JSJejIhXSo/XafWaiRFxSOnxgRFxR0T8tLTtfyNit2XcdkBE3BYRb0TE3yLinIi4dBk+00dK+301IiZFxBdarRsaEY+W9vFMRBxTWr566XO+GhEvR8TtEbHQ78GI2AD4GtCcUvpHSmlOSmkSsBewa0TsGBEfj4jnIqJbq9ftEREPlx43RMSxEfGfiHgpIi6PiA+W1vWPiBQRB0fENODmZfj8EyPixxFxT0S8FhFXz3//0vovlNrl1dK2H2m1rl9E/Kn0b/9SRJzd5r07+rc7MCKeKrXrf5e2d1XSggxhUtexJvBBoAkYQf75v7D0vBF4Czi7w1fDNsATwOrAT4DzIyKWYdvfAfcAqwGjgP2X9oNExArAn4EbgTWAI4FxEbFRaZPzga+mlFYFNqUl5BwNTAc+BPQBjgfau3bbTsD0lNI9rRemlJ4G7gJ2TindBbwJ7Nhqk31Lnw/gG8AXgR2AtYFXgHPa7GcHcs/aZ5b0s7fxZeCg0vvPIffeEREbApcBR5E/6wTgzxGxYik0/gWYCvQH+gLjW71nu/92EdGz9P67ldr1E8CDy1i3JAxhUlcyDzgxpfROSumtlNJLKaUrUkqzU0pvAKPJoaAjU1NK56aU5gIXA2uRg8wSbxsRjcDWwAkppXdTSncA1yzDZ/k40As4tfQ+N5ODxfDS+veAjSPifSmlV1JKD7RavhbQlFJ6L6V0e2r/ArqrA892sO9nS+shB53hABGxKjC0tAzgq8DIlNL0lNI75MC5d0S0PgxkVErpzZTSWx3sa+1ST1brW89W63+bUnokpfQm8APg/0ohax/g2pTSX1NK7wE/BVYhB6dB5ND2ndK+3y79O8y3qH/necCmEbFKSunZUu+gpGVkCJO6jhdTSm/PfxIRPSLiNxExNSJeB24DerceXmvjufkPUkqzSw97LeW2awMvt1oG8PRSfg5K7/N0Smleq2VTyb06kIcNhwJTI+LWaDmY/XRgMnBjaVjt2A7efyY5fLRnrdJ6yL1ee0Y+WH9P4IGU0tTSuibgyvnhCXgMmMuCwXVxn31GSql3m9ubHbx+KrACOSCuXXoOQKmdnia3Tz9y0OromMB2/+1K+90HOAx4NiKujYgPL6Z+SYtgCJO6jrY9PkeTDzbfJqX0PuBTpeUdDTF2hmeBD0ZEj1bL+i3D+8wA+rU5nqsReAYgpXRvSml38lDlVcDlpeVvpJSOTimtC3we+HZE7NTO+99cev9BrRdGRD9yL9xNpfd7lBx2dmPBoUjIoWe3NgFq5ZTSM622aa8Xbmm0brtGck/fTHL7NLWqO0rbPlOqq7FNj9wSSSndkFLamRxEHwfOXfbSJRnCpK5rVfJxYK+WDug+sdw7LPUS3QeMKh2ftC05DC1SRKzc+kY+puxN4LsRsUJEDC69z/jS+zZHxPtLQ3Gvk3ugiIjPRcT6pVAyf/ncdup8EhhDPs7s4xHRLSI2Aa4A/tbmjNPfkY//+hTwh1bLxwCjI6KptO8PRUSnnlUJ7BcRG5dC7cnAH0vDiJcDn42InUrHzx0NvAPcSW67Z4FTI6JnqU23W9yOIqJP6WD/nqX3mkU7bSdpyRnCpK7rTPJxQjPJB5tfX6H9NgPbAi8BPwJ+T/6j3pG+5LDY+tYP+AK5B2om8Cvgyymlx0uv2R+YUhpmPQzYr7R8A+Bv5ADxD+BXKaWJHez3COA84NLS9tcDE8lDna1dBgwGbk4pzWy1/Bfk491ujIg3yG28zSI+Z3vWjoXnCWu9/98CF5GHEFcmh0FSSk+QP/NZ5Pb5PPD50vFzc0vP1wemkU9U2GcJamkgh7kZwMvk4we/tpSfR1Ir0f4xqZJUGRHxe+DxlFLZe+LqSURMBC5NKZ1XdC2Slo09YZIqKiK2joj1SvNo7Uqe+PSqouuSpEpzxnxJlbYm8CfyPGHTgcNTSv8stiRJqjyHIyVJkgrgcKQkSVIBDGGSJEkFqLljwlZfffXUv3//osso3JtvvknPnj0Xv2Gdsx1a2BYtbIsWtkVmO7SwLVpUoi3uv//+mSmlD7W3ruZCWP/+/bnvvvuKLqNwEydOZPDgwUWXUTjboYVt0cK2aGFbZLZDC9uiRSXaIiKmdrTO4UhJkqQCGMIkSZIKYAiTJEkqgCFMkiSpAIYwSZKkAhjCJEmSCmAIkyRJKoAhTJIkqQCGMEmSpAIYwtoYNw7694eGhnw/blzRFUmSpHpUc5ctKqdx42DECJg9Oz+fOjU/B2huLq4uSZJUf+wJa2XkyJYANt/s2Xm5JElSZyprCIuIXSPiiYiYHBHHtrP+OxHxYOn2SETMjYgPlrOmRZk2bemWS5IkLauyhbCI6AacA+wGbAwMj4iNW2+TUjo9pfSxlNLHgOOAW1NKL5erpsVpbFy65ZIkScuqnD1hg4DJKaWnUkrvAuOB3Rex/XDgsjLWs1ijR0OPHgsuW2WVvFySJKkzlTOE9QWebvV8emnZQiKiB7ArcEUZ61ms5mYYOxaamiAi3wYMgGHDiqxKkiTVo0gpleeNI74EfCaldEjp+f7AoJTSke1suw+wX0rp8x281whgBECfPn22Gj9+fFlqbmvChDU5/fQPc9BB/2X//adWZJ9LatasWfTq1avoMgpnO7SwLVrYFi1si8x2aGFbtKhEWwwZMuT+lNLA9taVc4qK6UC/Vs/XAWZ0sO0wFjEUmVIaC4wFGDhwYBo8eHAnlbhoO+wAM2bARRcN4MADB7D99hXZ7RKZOHEilWqHamY7tLAtWtgWLWyLzHZoYVu0KLotyjkceS+wQUQMiIgVyUHrmrYbRcT7gR2Aq8tYyzKJgF//GtZbD4YPh5kzi65IkiTVi7KFsJTSHOAI4AbgMeDylNKkiDgsIg5rtekewI0ppTfLVcvyWHVVuPxyePFFOPBAmDev6IokSVI9KOs8YSmlCSmlDVNK66WURpeWjUkpjWm1zUUppao+9P1jH4Of/xyuvRbOOKPoaiRJUj1wxvwl9LWvwZ57wrHHwj33FF2NJEmqdYawJRQB558P66wD++wDr75adEWSJKmWGcKWQu/eMH48TJ8OhxwCZZrdQ5IkdQGGsKW0zTbw4x/DFVfAmDGL316SJKk9hrBl8O1vw9Ch8K1vwYMPFl2NJEmqRYawZdDQABdfDKutlo8PmzWr6IokSVKtMYQto9VXh9/9DiZPhsMP9/gwSZK0dAxhy2GHHWDUKLj00twzJkmStKQMYcvp+ONhxx3h61+HRx8tuhpJklQrDGHLqVu33BPWs2c+Puytt4quSJIk1QJDWCdYa60cxB55BI46quhqJElSLTCEdZJddsmXNBo7Nk/oKkmStCiGsE508snwiU/AiBH5rElJkqSOGMI60QorwGWXQffuMGwYvPNO0RVJkqRqZQjrZI2NcNFFcP/98L3vFV2NJEmqVoawMvjCF+Cb34Rf/AKuvrroaiRJUjUyhJXJaafBVlvBV74C06YVXY0kSao2hrAyWWkl+P3vYc4cGD4c3nuv6IokSVI1MYSV0Xrrwbnnwp13wgknFF2NJEmqJoawMttnnzxlxamnwg03FF2NJEmqFoawCjjzTNh0U9h/f3j22aKrkSRJ1cAQVgGrrAKXXw5vvgnNzTB3btEVSZKkohnCKuQjH4FzzoFbboHRo4uuRpIkFc0QVkEHHJCHJE86CW69tehqJElSkQxhFRQBv/oVrL8+fPGL0K8fNDRA//4wblzR1UmSpEoyhFVYr165R+zVV2H6dEgJpk7NZ1AaxCRJ6joMYQUYO3bhZbNnw8iRla9FkiQVwxBWgI4uY+TljSRJ6joMYQVobFy65ZIkqf4YwgowejT06LHgsoYGGDWqkHIkSVIBDGEFaG7Ox4U1NeUzJj/0IZg3D26/PR+oL0mS6p8hrCDNzTBlSg5fL7wAP/gBXHAB/OY3RVcmSZIqwRBWJUaNgqFD4RvfgL//vehqJElSuRnCqkRDQ54nrKkJ9t4bZswouiJJklROhrAq0rs3XHklvPFGDmLvvFN0RZIkqVwMYVVm003hoovgH/+Ab36z6GokSVK5GMKq0N57w7HH5oP0zzuv6GokSVI5GMKq1I9+BLvsAl//Otx9d9HVSJKkzmYIq1LdusFll0HfvrDXXvDcc0VXJEmSOpMhrIp98INw1VXwyivwpS/Bu+8WXZEkSeoshrAqt/nmcP75cMcdcPTRRVcjSZI6S/eiC9DiDRsG990HP/sZbLUVHHhg0RVJkqTlZQirEaeeCv/8Jxx2WJ7GQpIk1bayDkdGxK4R8URETI6IYzvYZnBEPBgRkyLi1nLWU8u6d4ff/x7WXBP23BNeeWWFokuSJEnLoWwhLCK6AecAuwEbA8MjYuM22/QGfgV8IaW0CfClctVTD1ZfHf70J3jxRTjppE14772iK5IkScuqnD1hg4DJKaWnUkrvAuOB3dtssy/wp5TSNICU0gtlrKcubLkljB0LDz3Um+9+t+hqJEnSsoqUUnneOGJvYNeU0iGl5/sD26SUjmi1zZnACsAmwKrAL1JKl7TzXiOAEQB9+vTZavz48WWpuZaccUYj11yzLscf/yg779x1s+usWbPo1atX0WVUBduihW3RwrbIbIcWtkWLSrTFkCFD7k8pDWxvXTkPzI92lrVNfN2BrYCdgFWAf0TEXSmlJxd4UUpjgbEAAwcOTIMHD+78amvMnDm38tpr63LGGRuz994bs8UWRVdUjIkTJ+L3IbMtWtgWLWyLzHZoYVu0KLotyjkcOR3o1+r5OsCMdra5PqX0ZkppJnAb8NEy1lQ3undPXH45rLYa7LEHzJxZdEWSJGlplDOE3QtsEBEDImJFYBhwTZttrga2j4juEdED2AZ4rIw11ZU11sgH6j/3XJ5LbM6coiuSJElLqmwhLKU0BzgCuIEcrC5PKU2KiMMi4rDSNo8B1wMPA/cA56WUHilXTfVo663h17+Gm26C448vuhpJkrSkyjpZa0ppAjChzbIxbZ6fDpxezjrq3Ve+kmfUP/30PKP+PvsUXZEkSVocrx1ZJ844A7bbDg46CB5+uOhqJEnS4hjC6sSKK8If/wi9e+cD9V9+ueiKJEnSohjC6siaa8IVV8DTT8O++8LcuUVXJEmSOmIIqzMf/ziccw7ccAP84AdFVyNJkjpiCKtDhx6abz/+ce4ZkyRJ1ccQVqfOOgu22QYOOAAmTSq6GkmS1JYhrE6ttFLuBevVC3baCfr1g4YG6N8fxo0rujpJkmQIq2N9+8KIEfD88zB9OqQEU6fmZQYxSZKKZQirc5dcsvCy2bNh5MjK1yJJkloYwurctGlLt1ySJFWGIazONTa2v7xfv8rWIUmSFmQIq3OjR0OPHgsv790b3nyz8vVIkqTMEFbnmpth7FhoaoKIfH/IIfDII7Dzzl7eSJKkohjCuoDmZpgyBebNy/fnnpuvM3n//bDDDjBjRtEVSpLU9RjCuqg99oDrr8+hbLvtYPLkoiuSJKlrMYR1YUOGwC23wKxZOYj9859FVyRJUtdhCOviBg6EO+7IM+wPHgy33VZ0RZIkdQ2GMLHRRvD3v8Paa8NnPgN//nPRFUmSVP8MYQLyvGG33w6bbZaPF2tvpn1JktR5DGH6n9VXh5tuyseKHXAAnHFG0RVJklS/DGFawKqrwl/+AnvvDd/+Nnz/+/nC35IkqXMZwrSQlVaC8eNhxIg84/7hh8PcuUVXJUlSfeledAGqTt26wZgxeYjylFPyzPq//W0OaJIkafkZwtShiNwTttpqcPTR8Oqr8Kc/Qa9eRVcmSVLtczhSi/Xtb8NFF8HNN8NOO8FLLxVdkSRJtc8QpiVywAG5F+yhh2D77WH69KIrkiSpthnCtMS+8AW44QZ45pl8maMnnyy6IkmSapchTEtlhx1g4kR4+2345CfhgQeKrkiSpNpkCNNS22KLfL3JHj3y9SYnTiy6IkmSao8hTMtkgw3y9SYbG2HXXeGqq4quSJKk2mII0zLr2xduuy33jO21F1x4YdEVSZJUOwxhWi4f/CD87W+w885w0EGw777Qvz80NOT7ceOKrlCSpOrkZK1abj17wjXX5IP2L7usZfnUqfnSRwDNzcXUJklStbInTJ1ixRVhxoyFl8+eDSNHVr4eSZKqnSFMnebpp9tfPm1aZeuQJKkWGMLUaRobl265JEldmSFMnWb06Dx3WFuHH175WiRJqnaGMHWa5mYYOxaamiAiT2HRuzeccw48+2zR1UmSVF0MYepUzc0wZQrMm5cv8n3zzfDyy/D5z8ObbxZdnSRJ1cMQprLaYgsYPx7++c88h9jcuUVXJElSdTCEqew+9zn4xS/yXGLHHFN0NZIkVQcna1VFHHEE/Oc/cOaZsN56+bkkSV1ZWXvCImLXiHgiIiZHxLHtrB8cEa9FxIOl2wnlrEfF+ulPYffd4ZvfhL/8pehqJEkqVtlCWER0A84BdgM2BoZHxMbtbHp7SuljpdvJ5apHxevWLV9LcostYNgweOCBoiuSJKk45ewJGwRMTik9lVJ6FxgP7F7G/akG9OwJf/4zrLZaPlaso1n2JUmqd5FSKs8bR+wN7JpSOqT0fH9gm5TSEa22GQxcAUwHZgDHpJQmtfNeI4ARAH369Nlq/PjxZam5lsyaNYtevXoVXcYy++9/e3LkkVvQp8/bnHXWP+nRY9lOm6z1duhMtkUL26KFbZHZDi1sixaVaIshQ4bcn1Ia2N66ch6YH+0sa5v4HgCaUkqzImIocBWwwUIvSmksMBZg4MCBafDgwZ1cau2ZOHEitdwOgwfnyVyHDu3FWWdtz5//DN2X4dtY6+3QmWyLFrZFC9sisx1a2BYtim6Lcg5HTgf6tXq+Drm3639SSq+nlGaVHk8AVoiI1ctYk6rILrvAr38N118PRx4JZeqUlSSpKpWzJ+xeYIOIGAA8AwwD9m29QUSsCTyfUkoRMYgcCl8qY02qMocemqeuOO00WH99OProoiuSJKkyyhbCUkpzIuII4AagG3BBSmlSRBxWWj8G2Bs4PCLmAG8Bw1K5DlJT1TrlFHjqKfjOd2DAANhzz6IrkiSp/Mo6WWtpiHFCm2VjWj0+Gzi7nDWo+jU0wMUX5zMl99sPJk6EQYOKrkqSpPLyskWqCqusAldfDWuumS/2PWVK0RVJklRehjBVjTXWgGuvhXffhc9+Fl59teiKJEkqH0OYqspHPgJXXgn//jfsvXcOZJIk1SNDmKrO4MFw7rlw001w+OFOXSFJqk9lPTBfWlYHHJDPmDz5ZFhvPTj++KIrkiSpcxnCVLVGjYLJk2HkSFh33XzRb0mS6oUhTFUrAi64IE9dceCB0K8fbLdd0VVJktQ5PCZMVW2llfKB+o2NsPvuuWdMkqR6YAhT1VttNZhQmvJ36FB4yQtbSZLqgCFMNWH99fNkrlOnwh57wDvvFF2RJEnLxxCmmrHddnDRRXD77XDwwU5dIUmqbYYw1ZThw+FHP4Jx4+ADH4Add9yB/v3zc0mSaolnR6rm9O8P3brBa68BBFOnwogReV1zc4GFSZK0FOwJU80ZORLmzl1w2ezZebkkSbXCEKaaM23a0i2XJKkaGcJUcxob21/ep09l65AkaXkYwlRzRo+GHj0WXBaRjxF78MFiapIkaWkZwlRzmpth7FhoaoKIRFMTnHFGntR1l13g8ceLrlCSpMUzhKkmNTfDlClw8823MmUKfPObcNNN0NAAO+0ETz1VdIWSJC2aIUx1Y8MN4a9/hbfegk9/GqZPL7oiSZI6ZghTXdlsM7jhBpg5MwexF14ouiJJktpnCFPd2XpruPbaPGXFLrvAK68UXZEkSQszhKkubb89XHUVPPYY7LYbvPFG0RVJkrQgQ5jq1i67wOWXw333wec/n2fVlySpWhjCVNd23x0uuQRuuw322gveeafoiiRJygxhqnv77pvnFbv++vx4zpyiK5IkyRCmLuKQQ/KErn/6Exx0EMybV3RFkqSurnvRBUiVctRR8Oab8P3vQ8+e8Ktf5csdSZJUhCUKYRHRE3grpTQvIjYEPgxcl1J6r6zVSZ3s+OPzmZKnnZaD2OmnG8QkScVY0p6w24DtI+IDwE3AfcA+QHO5CpPKIQJ+/GOYNQt+9jNYdVU48cSiq5IkdUVLGsIipTQ7Ig4Gzkop/SQi/lnOwqRyiYBf/jIPTY4alXvEjjmm6KokSV3NEoewiNiW3PN18FK+Vqo6DQ1w3nl57rDvfAd69YLDDiu6KklSV7KkQeoo4DjgypTSpIhYF7ilfGVJ5detG/z2tzmIfe1ruUds//2LrkqS1FUsUQhLKd0K3AoQEQ3AzJTSN8pZmFQJK64If/gDfPazcOCB0KNHntRVkqRyW6J5wiLidxHxvtJZko8CT0TEd8pbmlQZK68MV18N22wDw4fDddcVXZEkqStY0slaN04pvQ58EZgANAIO3Khu9OoFEybAppvCnnvCxIlFVyRJqndLGsJWiIgVyCHs6tL8YKl8ZUmV17s33HgjrLsufO5zcNddRVckSapnSxrCfgNMAXoCt0VEE/B6uYqSirL66vDXv8Kaa8Juu8GDDxZdkSSpXi1RCEsp/TKl1DelNDRlU4EhZa5NKsTaa8NNN+Uhyl12gccfL7oiSVI9WtID898fET+PiPtKt5+Re8WkutTUlINYQwNsuy307Zsf9+8P48YVXZ0kqR4s6XDkBcAbwP+Vbq8DF5arKKkabLhhvuj3q6/CjBmQEkydCiNGGMQkSctvSUPYeimlE1NKT5VuJwHrlrMwqRqMGbPwstmzYeTIytciSaovSxrC3oqIT85/EhHbAW8t7kURsWtEPBERkyPi2EVst3VEzI2IvZewHqkipk1buuWSJC2pJQ1hhwHnRMSUiJgCnA18dVEviIhuwDnAbsDGwPCI2LiD7U4DbliKuqWKaGxsf3m3bnDffZWtRZJUX5b07MiHUkofBTYHNk8pbQHsuJiXDQIml4Yv3wXGA7u3s92RwBXAC0tetlQZo0fnSxm1ttJK+czJj38cTjoJ3nuvmNokSbVtSXvCAEgpvV6aOR/g24vZvC/wdKvn00vL/ici+gJ7AO0ceSMVr7kZxo7NZ0tG5Pvzz4ennsqXOBo1Cj7xCaexkCQtvUhp2Sa+j4inU0r9FrH+S8BnUkqHlJ7vDwxKKR3Zaps/AD9LKd0VERcBf0kp/bGd9xoBjADo06fPVuPHj1+mmuvJrFmz6NWrV9FlFK7odrj11g/x859vyNtvN3DooU+x557P0LBU/7XpPEW3RTWxLVrYFpnt0MK2aFGJthgyZMj9KaWB7a5MKS3TDZi2mPXbAje0en4ccFybbf5Lnol/CjCLPCT5xUW971ZbbZWU0i233FJ0CVWhGtrh2WdT+tznUoKUhgxJaerUYuqohraoFrZFC9sisx1a2BYtKtEWwH2pg0yzyP+zR8QbEfF6O7c3gLUXE/7uBTaIiAERsSIwDLimTQAckFLqn1LqD/wR+FpK6arFvK9UVdZcE665Bs47D+69FzbbDC6+OM8rJklSRxYZwlJKq6aU3tfObdWUUvfFvHYOcAT5rMfHgMtTSpMi4rCIOKzzPoJUvAg4+GB4+GH46EfhwANhzz3hBU83kSR1YJFBanmllCYAE9osa/cg/JTSgeWsRaqEAQPgllvgzDPh+ONh003h3HNh9/bOC5YkdWkFHUIs1a9u3eDoo+H++2GddeCLX4SvfAVee63oyiRJ1cQQJpXJppvCXXfB978Pv/0tbL557iWTJAkMYVJZrbgi/PCH8Pe/50led9wRvvUteGuxF/2SJNU7Q5hUAdtsAw8+CEcckY8X23JLL3skSV2dIUyqkB494Kyz4MYb4Y038mWPRo3yskeS1FUZwqQK23lneOSRfNmjk06CbbeFxx4ruipJUqUZwqQC9O6dD9b/4x9hypQ8PHnmmXDppdC/PzQ05Ptx4wouVJJUNmWdJ0zSou21F2y3HRx6aD5gv6EB5s3L66ZOhREj8uPm5uJqlCSVhz1hUsHmX/ZotdVaAth8s2fDyJHF1CVJKi9DmFQFIuDll9tfN21aZWuRJFWGIUyqEo2N7S9fa63K1iFJqgxDmFQlRo/O01i0NXOmB+hLUj0yhElVorkZxo6FpqY8PNnUlOcV22Yb2G+/fPC+M+1LUv0whElVpLk5T1kxb16+P+IIuPlmOP54OO+8HMgef7zoKiVJncEQJlW57t3zUOX118Ozz8LAgQ5PSlI9MIRJNeIzn8nXn9xyS4cnJakeGMKkGtK3r8OTklQvDGFSjXF4UpLqgyFMqlFthydPP30jZs8uuipJ0pIyhEk1bP7w5MiRMGHCWg5PSlINMYRJNa57d/jRj+C00x7iuefy8OSllxZdlSRpcQxhUp0YNOiV/w1P7r8/HHIIDk9KUhUzhEl1pPXw5Pnne/akJFUzQ5hUZ+YPT15/PQ5PSlIVM4RJdWr+2ZNbbeXwpCRVI0OYVMf69oWbbsrDkxdc4PCkJFUTQ5hU5+YPT153XQ5a7/8AABmCSURBVMvw5OGHQ//+0NCQ753sVZIqzxAmdRHzhyfXWQfGjIGpUyGlfD9ihEFMkirNECZ1IX37tn/R79mz85ClJKlyDGFSF/P00+0vnzatsnVIUldnCJO6mMbG9pf36gXvvlvZWiSpKzOESV3M6NHQo8eCy7p3hzfegMGDYfr0QsqSpC7HECZ1Mc3NMHYsNDVBRL6/6CK4/HL4179giy3gr38tukpJqn+GMKkLam6GKVNg3rx839wMX/oS3Hcf9OmTz6Q8+eS8XpJUHoYwSf+z0UZw992w335w4okwdCjMnFl0VZJUnwxhkhbQsydcfHGeS+yWW2DLLXMwkyR1LkOYpIVEwFe/Cn//e55Vf/vt4eyz8+SukqTOYQiT1KGBA+GBB2CXXeDII2HffWHWrKKrkqT6YAiTtEgf/CBccw2ccko+g3LQIHj00aKrkqTaZwiTtFgNDXDccXnqipdeykHsssuKrkqSapshTNIS23HHPDy5xRZ5aPLrX4d33im6KkmqTYYwSUulb1+4+WY4+mj41a/gU5+CqVOLrkqSak9ZQ1hE7BoRT0TE5Ig4tp31u0fEwxHxYETcFxGfLGc9kjrHCivAT38KV1wBjz+ep7G47rqiq5Kk2lK2EBYR3YBzgN2AjYHhEbFxm81uAj6aUvoYcBBwXrnqkdT59twzz7K/zjrw2c/CCSfA3LlFVyVJtaGcPWGDgMkppadSSu8C44HdW2+QUpqV0v9mHuoJOAuRVGM22ADuugsOPBB++EPYdVd48cWiq5Kk6lfOENYXeLrV8+mlZQuIiD0i4nHgWnJvmKQas8oqcMEFcN55cPvt+cD9O+8suipJqm6RyjQFdkR8CfhMSumQ0vP9gUEppSM72P5TwAkppU+3s24EMAKgT58+W40fP74sNdeSWbNm0atXr6LLKJzt0KJa2uLf/+7FqFGb8PzzK3HYYU+x117TiahsDdXSFtXAtshshxa2RYtKtMWQIUPuTykNbHdlSqksN2Bb4IZWz48DjlvMa/4LrL6obbbaaquklG655ZaiS6gKtkOLamqLV15JaffdU4KUBg1KqV+/lCJSampK6dJLy7//amqLotkWme3QwrZoUYm2AO5LHWSacg5H3gtsEBEDImJFYBhwTesNImL9iPx/5IjYElgReKmMNUmqgN694corYZ994J574Omn83Unp06FESNg3LiiK5Sk4pUthKWU5gBHADcAjwGXp5QmRcRhEXFYabO9gEci4kHymZT7lFKjpBoXkQ/Yb2v2bBg5svL1SFK16V7ON08pTQAmtFk2ptXj04DTylmDpOJMm7Z0yyWpK3HGfEll09jY8bpLLslDlJLUVRnCJJXN6NHQo8eCy1ZZJc8tdsABsPfezikmqesyhEkqm+ZmGDsWmpryMWJNTXDuufDoo3DaafCXv8Bmm+V7SepqDGGSyqq5GaZMgXnz8n1zM3TrBt/9Ltx7L/TpA5//PBx6KLzxRtHVSlLlGMIkFWbzzfMUFscem2fc/+hH84z7ktQVGMIkFWqlleDHP4bbbstDljvskHvJ3nmn6MokqbwMYZKqwnbbwUMP5WHJ00+HgQPzc0mqV4YwSVWjVy/4zW/g2mth5kzYems49VSYO7foyiSp8xnCJFWdoUPhX/+C3XeH446DT30K/vOfoquSpM5lCJNUlVZfHS6/HC69FCZNygftjx3rBK+S6ochTFLVishTWvzrX/Dxj8NXvwqf/Sw8+2zRlUnS8jOESap6/frBjTfCWWfBxImw6abwhz8UXZUkLR9DmKSa0NAARxwB//wnrLce/N//wX77wSuvFF2ZJC0bQ5ikmrLRRnDnnXDSSTB+fL7s0d/+VnRVkrT0DGGSak737nDCCXDXXbDqqrDzzvCNb8CFF0L//rDjjjvQvz+MG1d0pZLUse5FFyBJy2rgQHjgATj+eDjzzHwgfz57Mpg6FUaMyNs1NxdZpSS1z54wSTVtlVXgjDNgjTUWnr5i9mwYObKYuiRpcQxhkurCiy+2v3zq1HxR8HnzKluPJC2OIUxSXWhsbH95RJ5xv7ERjj4a7r3XCV8lVQdDmKS6MHo09Oix4LIePeC88+B3v4OttoKzz4ZBg2D99fNxZA8/bCCTVBxDmKS60NycL2vU1AQRiaam/Pygg2D4cLj6anj++XwG5QYbwE9+ki+FtMkmcPLJ8MQTRX8CSV2NIUxS3WhuhilT4Oabb2XKlIXPiuzdGw48EK6/Pl/66Ne/zgf0jxoFH/4wbLklnHZafg9JKjdDmKQu6UMfgsMOy5dBevrpfIbliivCscfCgAGw7bbwi1/AjBlFVyqpXhnCJHV5ffvCUUflyV+fegpOPRXefjsvW2cdGDIExoxZ8AzMcePyxLANDTgxrKRlYgiTpFYGDIDvfS9fo/Kxx+DEE+G55+Dww2GttWDXXeGrX4VDD83TX6TE/yaGNYhJWhqGMEnqwIc/nEPYo4/Cgw/Cd78LTz6ZD/h/660Ft3ViWElLyxAmSYsRkc+kPOUU+M9/8vP2TJ0KX/saXHwxPP64E8RKWjSvHSlJSyEiT/w6derC61ZaCS69NJ91CflszK23hm22abl96EOVrVdS9TKESdJSGj06HwM2e3bLsh498jDlsGG5F+zuu1tup5zS0is2YMCCoWyLLWDllYv5HJKKZQiTpKU0f/6xkSNh2rTcMzZ6dMvyTTbJt4MOys/ffBPuv78llN1xB4wfn9etsEIe6pwfygYNypPJNpQOFhk3ruP9SKpthjBJWgbNzUsehnr2zNev/NSnWpbNmLFgb9nFF8M55+R1vXvnMNajB1x3HbzzTl4+/yzM+fuXVNsMYZJUgLXXhj32yDeAuXPzWZh33w333JPvH3544dfNPwvTECbVPkOYJFWBbt1gs83y7ZBD8rKGhvYvMD5tWmVrk1QeTlEhSVWqsbH95d265dn9JdU2Q5gkVanRo/NxYa2ttBK8732w3XZ5Zv+33y6mNknLzxAmSVWquTlPe9HUlOcna2qC88+H//4XDj4YfvIT2HLLfAyZpNpjCJOkKtbcDFOm5HnGpkzJz9/3vhzOrr8e3ngDtt0Wjjuu5SxKSbXBECZJNeozn4FHHoGvfAVOPTX3it17b9FVSVpShjBJqmHvfz+cdx5MmACvvZZ7xUaOtFdMqgWGMEmqA7vtlnvFvvzlfJmkgQPzLP2SqpchTJLqRO/ecMEFcO218PLL+TJI558/wF4xqUoZwiSpzgwdmnvF9tsPLr20iYED4YEHiq5KUluGMEmqQx/4AFx0EZxyysO89FK+FuUJJ8C77xZdmaT5yhrCImLXiHgiIiZHxLHtrG+OiIdLtzsj4qPlrEeSupptt32ZSZNg333hhz+ErbeGBx8suipJUMYQFhHdgHOA3YCNgeERsXGbzf4L7JBS2hz4ITC2XPVIUlf1gQ/AJZfANdfACy/kIDZqlL1iUtHK2RM2CJicUnoqpfQuMB7YvfUGKaU7U0qvlJ7eBaxTxnokqUv7/Odh0iQYNgxOOikPUT70UNFVSV1XpJTK88YRewO7ppQOKT3fH9gmpXREB9sfA3x4/vZt1o0ARgD06dNnq/Hjx5el5loya9YsevXqVXQZhbMdWtgWLWyLFh21xR13rMbPf74Rr7/enf33n0pz8zS6dy/P34Nq4HeihW3RohJtMWTIkPtTSgPbXZlSKssN+BJwXqvn+wNndbDtEOAxYLXFve9WW22VlNItt9xSdAlVwXZoYVu0sC1aLKotZs5Mad99U4KUttgipVNOSampKaWIfH/ppeWr69JLK7evlPxOtGZbtKhEWwD3pQ4yTTmHI6cD/Vo9XweY0XajiNgcOA/YPaX0UhnrkSS1stpqMG4cXHklTJ4Mxx8PU6dCSvl+xAi49NL8vDONG5ffu+2+xo3r3P1I1a57Gd/7XmCDiBgAPAMMA/ZtvUFENAJ/AvZPKT1ZxlokSR344hfz5Y/eeGPB5bNnw/7751sENDQs3a2j10yZAnPmLLyvkSPzBcqlrqJsISylNCcijgBuALoBF6SUJkXEYaX1Y4ATgNWAX0UEwJzU0bipJKlsnnmm43WjRsG8eZ13mzy5/f1Mm1aWjyZVrXL2hJFSmgBMaLNsTKvHhwALHYgvSaqsxsY8LNhWUxOceGLn7uvvf29/XxHws5/B4YdDjx6du0+pGjljviSJ0aMXDj49euTlldjXyivDxhvDMcfAuuvCL34Bb7/d+fuWqokhTJJEczOMHZt7viLy/dix5TlGq719nXce/OtfcPvtsMkmcNRRsN568Ktf4QXIVbcMYZIkIIejKVPycVtTppT3IPmO9vXJT8JNN8Ett+Qesa9/HTbYIIc2Z/hXvTGESZKqzuDBcNtt8Ne/Qt++8NWvwkYbwYUXLnxmpVSrDGGSpKoUAZ/+NNx5J0yYAKuvDgcdBB/5CPz2tzB3btEVSsvHECZJqmoRsNtucM89cPXV0LMnfPnL+dix8ePzkKZUiwxhkqSaEAFf+AI88ABccQWssAIMHw6bbw5//KNhTLXHECZJqikNDbDnnvDQQ7knbO5c+NKXYIst4KqrOv8yS1K5GMIkSTWpoQH22QceeSRf4/Ktt2CPPWDgQLj22sqHsXHjoH//XFf//uW9FmYl96XyMYRJkmpat255iotHH81nT77yCnzuc7DttnDssXkesh133KHTw0pKedqM117L85kdeuiCFyU/5BA444x8OaYZM+D55+Gll/L2s2blyWjnzFn6sOgF0OtHWS9bJElSpXTvDgcemAPZxRfD974Hd989f20wdWo+u/KOO2DLLXPP2ZLc3n6743WLOg7t7bfh29/Ot8VpaMj1d++eQ2V7j+c/f+opeO+9BV/vBdBrkyFMklRXVlgh90L98Ifw8ssLrnv3XRgzZuHXrLgirLJK+7dVV4U11siXVupom2OO6bie887LPV5z5+b75X38xBPt78cLoNceQ5gkqS49/XT7yyPyEN78ALXyyrmHaXmcdVbHF0A/+ODle++27r67/X2tsgpMnw7rrNO5+1P5eEyYJKkuNTZ2vLxfvzz5a8+eyx/AoPgLoK+wQu7l+/CH4Sc/8RJPtcIQJkmqS5UMRkVfAP3CC+HJJ/MVBr73PfjoR/M1OFXdDGGSpLq0YFhJZQ1G8/dX5AXQBwzI86T95S+5J+zTn85TeEyfXr46tHwMYZKkujU/rNx8861lD0bV4rOfhUmT4OST4ZprHKKsZoYwSZLqzMorww9+kOdO22knhyirlSFMkqQ6NWBAvuh56yHKk07a2CHKKmEIkySpzs0fojzpJLjzztUcoqwShjBJkrqAlVeGE06Aiy661yHKKmEIkySpC1lrrbe5+mr4859bhiiHDYNnnim6sq7HECZJUhf0uc+1DFFefTVstBGcfrpDlJVkCJMkqYuaP0Q5/yzK734XPvYxuPnmoivrGgxhkiR1cfPPovzzn+Htt3MgGzYMzj4b+veHhoZ8P25c0ZXWF0OYJEkCWoYoR42CK66AI4/MFwtPKd+PGGEQ60yGMEmS9D+rrAInnghrrLHwutmz4VvfykHt7bcrX1u96V50AZIkqfo8+2z7y198ETbdtOXi4RtumA/q33DDlltjYx7C1KLZRJIkaSGNje0vX3NN+N3vcm/ZttvCSy/BRRflocvPfCYfX9ajB2y2Gey1Fxx3HFx4Idx5J8ycmYc22zNuXOWOP5u/rx133KHQY93sCZMkSQsZPTofAzZ7dsuyHj3gpz+F4cMX3DYleP55eOIJePLJltukSfki4nPmtGz7gQ8s3Hs2eTL88Ifw1lt5m/nHn0HnX3R93LjWnyvKuq/FMYRJkqSFzA8kI0fCtGm5Z2z06PaDSkTuIVtzTdhhhwXXzZkDU6bkUNY6pN18M1xyScf7nz0bDjoon6HZmR54YOG50GbPzp/TECZJkqpCc/PyB5Pu3WH99fNt6NAF182alXvBttyy/WHKd9+F971v+fbf3nu2Z9q0zt3PkjCESZKkQvTqlSeHbWzMQ5BtNTXBDTd07j77929/Xx0dA1dOHpgvSZIKNXp0Pt6stR498vJa3tfiGMIkSVKhmpth7Njc8zV/6ouxY8tzjNaC+0pl3dfiOBwpSZIK1xnHny3tviZOvJXBgwdXZqftsCdMkiSpAIYwSZKkAhjCJEmSCmAIkyRJKoAhTJIkqQCGMEmSpAKUNYRFxK4R8URETI6IY9tZ/+GI+EdEvBMRx5SzFkmSpGpStnnCIqIbcA6wMzAduDcirkkpPdpqs5eBbwBfLFcdkiRJ1aicPWGDgMkppadSSu8C44HdW2+QUnohpXQv8F4Z65AkSao65QxhfYGnWz2fXlomSZLU5ZXzskXRzrK0TG8UMQIYUXo6KyKeWOaq6sfqwMyii6gCtkML26KFbdHCtshshxa2RYtKtEVTRyvKGcKmA/1aPV8HmLEsb5RSGguM7Yyi6kVE3JdSGlh0HUWzHVrYFi1sixa2RWY7tLAtWhTdFuUcjrwX2CAiBkTEisAw4Joy7k+SJKlmlK0nLKU0JyKOAG4AugEXpJQmRcRhpfVjImJN4D7gfcC8iDgK2Dil9Hq56pIkSaoG5RyOJKU0AZjQZtmYVo+fIw9Tauk5PJvZDi1sixa2RQvbIrMdWtgWLQpti0hpmY6VlyRJ0nLwskWSJEkFMIRVqYjoFxG3RMRjETEpIr7ZzjaDI+K1iHiwdDuhiForISKmRMS/Sp/zvnbWR0T8snSJrIcjYssi6iy3iNio1b/3gxHxeulYytbb1O33IiIuiIgXIuKRVss+GBF/jYh/l+4/0MFrF3kZtVrTQVucHhGPl34GroyI3h28dpE/T7Wkg3YYFRHPtPoZGNrBa7vCd+L3rdphSkQ82MFr6+k70e7fz6r8XZFS8laFN2AtYMvS41WBJ8knLbTeZjDwl6JrrVB7TAFWX8T6ocB15PnpPg7cXXTNFWiTbsBzQFNX+V4AnwK2BB5ptewnwLGlx8cCp3XQVv8B1gVWBB5q+/NUa7cO2mIXoHvp8WnttUVp3SJ/nmrp1kE7jAKOWczrusR3os36nwEndIHvRLt/P6vxd4U9YVUqpfRsSumB0uM3gMfwigOLsjtwScruAnpHxFpFF1VmOwH/SSlNLbqQSkkp3Ua+5mxruwMXlx5fTPvXol3sZdRqTXttkVK6MaU0p/T0LrrAiU8dfCeWRJf4TswXEQH8H3BZRYsqwCL+flbd7wpDWA2IiP7AFsDd7azeNiIeiojrImKTihZWWQm4MSLuL11Boa2ueJmsYXT8C7WrfC8A+qSUnoX8yxdYo51tuuL34yBy73B7FvfzVA+OKA3LXtDBsFNX+05sDzyfUvp3B+vr8jvR5u9n1f2uMIRVuYjoBVwBHJUWnj/tAfJQ1EeBs4CrKl1fBW2XUtoS2A34ekR8qs36TrtMVi0oTYD8BeAP7azuSt+LJdXVvh8jgTnAuA42WdzPU637NbAe8DHgWfIwXFtd6jsBDGfRvWB1951YzN/PDl/WzrKyfS8MYVUsIlYgf4HGpZT+1HZ9Sun1lNKs0uMJwAoRsXqFy6yIlNKM0v0LwJXkLuPWOu0yWTViN+CBlNLzbVd0pe9FyfPzh55L9y+0s02X+X5ExAHA54DmVDrIpa0l+HmqaSml51NKc1NK84Bzaf/zdaXvRHdgT+D3HW1Tb9+JDv5+Vt3vCkNYlSqN358PPJZS+nkH26xZ2o6IGET+93ypclVWRkT0jIhV5z8mH3z8SJvNrgG+XDpL8uPAa/O7netUh/+r7Srfi1auAQ4oPT4AuLqdbbrEZdQiYlfge8AXUkqzO9hmSX6ealqb40H3oP3P1yW+EyWfBh5PKU1vb2W9fScW8fez+n5XFH0Wg7cOz+74JLkL9GHgwdJtKHAYcFhpmyOASeSzN+4CPlF03WVqi3VLn/Gh0ucdWVreui0COId8Vsu/gIFF113G9uhBDlXvb7WsS3wvyMHzWeA98v9YDwZWA24C/l26/2Bp27WBCa1eO5R8ltR/5n+HavnWQVtMJh/PMv93xpi2bdHRz1Ot3jpoh9+Wfg88TP4DulZX/U6Ull80//dDq23r+TvR0d/Pqvtd4Yz5kiRJBXA4UpIkqQCGMEmSpAIYwiRJkgpgCJMkSSqAIUySJKkAhjBJdSUi5kbEg61ux3bie/ePiJqdP0lSdeledAGS1MneSil9rOgiJGlx7AmT1CVExJSIOC0i7ind1i8tb4qIm0oXe74pIhpLy/tExJWlC6E/FBGfKL1Vt4g4NyImRcSNEbFKYR9KUk0zhEmqN6u0GY7cp9W611NKg4CzgTNLy84GLkkpbU6+4PUvS8t/Cdya8oXQtyTPJA6wAXBOSmkT4FVgrzJ/Hkl1yhnzJdWViJiVUurVzvIpwI4ppadKF/d9LqW0WkTMJF/W5r3S8mdTSqtHxIvAOimld1q9R3/grymlDUrPvweskFL6Ufk/maR6Y0+YpK4kdfC4o23a806rx3Px2FpJy8gQJqkr2afV/T9Kj+8EhpUeNwN3lB7fBBwOEBHdIuJ9lSpSUtfg/+Ak1ZtVIuLBVs+vTynNn6ZipYi4m/wf0OGlZd8ALoiI7wAvAl8pLf8mMDYiDib3eB0OPFv26iV1GR4TJqlLKB0TNjClNLPoWiQJHI6UJEkqhD1hkiRJBbAnTJIkqQCGMEmSpAIYwiRJkgpgCJMkSSqAIUySJKkAhjBJkqQC/D/1t6G4IhtISAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Define the model\n",
    "# 30 input features\n",
    "model = MLP_Mixer()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# List to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Append the average loss to the loss_values list\n",
    "    loss_values.append(avg_loss)\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to PyTorch tensors (if not already)\n",
    "x_test = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "y_test = torch.tensor(Y_test.values.astype(np.float32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.95      0.97      0.96        71\n",
      "   Malignant       0.95      0.91      0.93        43\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get predictions\n",
    "    test_predictions = model(x_test)\n",
    "    test_predictions_binary = (test_predictions > 0.5).numpy().flatten()\n",
    "    \n",
    "# Convert test labels to numpy\n",
    "y_test_binary = y_test.flatten()\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, test_predictions_binary)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_binary, test_predictions_binary, \n",
    "                             target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "Parameters:\n",
    "1. Learning Rate\n",
    "2. Number of MLP Mixer Blocks\n",
    "3. Token mixing hidden dimension\n",
    "4. Channel mixing hidden dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Mixer_Block(nn.Module):\n",
    "    def __init__(self, token_mix_hidden_dim, channel_mix_hidden_dim):\n",
    "        super(MLP_Mixer_Block, self).__init__()\n",
    "        self.token_mixing = nn.Sequential(\n",
    "            nn.Linear(1, token_mix_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(token_mix_hidden_dim, 1)\n",
    "        )\n",
    "        self.channel_mixing = nn.Sequential(\n",
    "            nn.Linear(30, channel_mix_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channel_mix_hidden_dim, 30)\n",
    "        )\n",
    "        self.layer_norm1 = nn.LayerNorm(30)\n",
    "        self.layer_norm2 = nn.LayerNorm(30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, 30]\n",
    "        # First layer norm\n",
    "        x_norm = self.layer_norm1(x)\n",
    "        \n",
    "        # Transpose for token mixing\n",
    "        x_mixed = x_norm.transpose(1, 2)  # [batch_size, 30, 1]\n",
    "        \n",
    "        # Token mixing\n",
    "        x_token_mixed = self.token_mixing(x_mixed)  # [batch_size, 30, 1]\n",
    "        \n",
    "        # Transpose back\n",
    "        x_token_mixed = x_token_mixed.transpose(1, 2)  # [batch_size, 1, 30]\n",
    "        \n",
    "        # Residual connection\n",
    "        x = x + x_token_mixed\n",
    "        \n",
    "        # Second layer norm\n",
    "        x_norm2 = self.layer_norm2(x)\n",
    "        \n",
    "        # Channel mixing\n",
    "        x_channel_mixed = self.channel_mixing(x_norm2.squeeze(1)).unsqueeze(1)\n",
    "        \n",
    "        # Final residual connection\n",
    "        x = x + x_channel_mixed\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP_Mixer(nn.Module):\n",
    "    def __init__(self, num_blocks, token_mix_hidden_dim, channel_mix_hidden_dim):\n",
    "        super(MLP_Mixer, self).__init__()\n",
    "        self.per_path_FC = nn.Linear(30, 30)\n",
    "        self.mixer_blocks = nn.ModuleList([MLP_Mixer_Block(token_mix_hidden_dim, channel_mix_hidden_dim) for _ in range(num_blocks)])\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input is [batch_size, features]\n",
    "        x = x.view(-1, 30)\n",
    "        x = self.per_path_FC(x)\n",
    "        \n",
    "        # Add token dimension\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, features]\n",
    "        \n",
    "        # Apply mixer blocks\n",
    "        for block in self.mixer_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, features, 1]\n",
    "        x = self.global_avg_pool(x)\n",
    "        \n",
    "        # Classification head\n",
    "        x = x.view(-1, 30)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    num_blocks = trial.suggest_int('num_blocks', 1, 8)\n",
    "    token_mix_hidden_dim = trial.suggest_categorical('token_mix_hidden_dim', [32, 64, 128])\n",
    "    channel_mix_hidden_dim = trial.suggest_categorical('channel_mix_hidden_dim', [32, 64, 128])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train.values.astype(np.float32), dtype = torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.astype(np.float32), dtype = torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val.values.astype(np.float32), dtype = torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values.astype(np.float32), dtype = torch.float32)\n",
    "    \n",
    "    \n",
    "    # Create model, loss, and optimizer\n",
    "    model = MLP_Mixer(num_blocks, token_mix_hidden_dim, channel_mix_hidden_dim)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create the training dataset\n",
    "    training_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # Example usage with DataLoader\n",
    "    train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_preds = (val_outputs > 0.5).float()\n",
    "        accuracy = accuracy_score(y_val, val_preds.numpy())\n",
    "        auc = roc_auc_score(y_val, val_outputs.numpy())\n",
    "    \n",
    "    # Report multiple metrics\n",
    "    trial.set_user_attr('accuracy', accuracy)\n",
    "    trial.set_user_attr('auc', auc)\n",
    "    \n",
    "    return val_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "[I 2024-12-05 21:49:12,235] A new study created in memory with name: MLP Mixer Optimization\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:15,950] Trial 0 finished with value: 0.22790226340293884 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 128, 'learning_rate': 2.8326047717723405e-05}. Best is trial 0 with value: 0.22790226340293884.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:18,710] Trial 1 finished with value: 0.4932859539985657 and parameters: {'num_blocks': 5, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 64, 'learning_rate': 1.464739346103665e-05}. Best is trial 0 with value: 0.22790226340293884.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:22,659] Trial 2 finished with value: 0.12530559301376343 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0001783171677077637}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:25,966] Trial 3 finished with value: 0.17453904449939728 and parameters: {'num_blocks': 5, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 64, 'learning_rate': 5.301441974022293e-05}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:26,815] Trial 4 finished with value: 0.2502583861351013 and parameters: {'num_blocks': 1, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 128, 'learning_rate': 7.737433719973109e-05}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:29,334] Trial 5 finished with value: 0.2812388837337494 and parameters: {'num_blocks': 4, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 64, 'learning_rate': 0.003930972290739927}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:32,841] Trial 6 finished with value: 0.40398478507995605 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 64, 'learning_rate': 1.466595062753661e-05}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:36,217] Trial 7 finished with value: 0.1984080970287323 and parameters: {'num_blocks': 5, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 64, 'learning_rate': 3.8442428624864126e-05}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:38,252] Trial 8 finished with value: 0.1911824643611908 and parameters: {'num_blocks': 3, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0011622050951529482}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:40,780] Trial 9 finished with value: 0.1662759780883789 and parameters: {'num_blocks': 4, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 6.578918905996425e-05}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:45,254] Trial 10 finished with value: 0.1352723389863968 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.000339056381998726}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:49,790] Trial 11 finished with value: 0.19624938070774078 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0003353743972347968}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:54,299] Trial 12 finished with value: 0.21984252333641052 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0003502063587100781}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:49:58,462] Trial 13 finished with value: 0.1276645064353943 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0008186778734251312}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:02,447] Trial 14 finished with value: 0.19747935235500336 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0013319269416233485}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:06,348] Trial 15 finished with value: 0.3868674039840698 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0010487773911996073}. Best is trial 2 with value: 0.12530559301376343.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:10,402] Trial 16 finished with value: 0.1163448765873909 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00014979025127130928}. Best is trial 16 with value: 0.1163448765873909.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:11,827] Trial 17 finished with value: 0.13193145394325256 and parameters: {'num_blocks': 2, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 128, 'learning_rate': 0.00010993383519142263}. Best is trial 16 with value: 0.1163448765873909.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:15,256] Trial 18 finished with value: 0.18730182945728302 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00020254767197394656}. Best is trial 16 with value: 0.1163448765873909.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:19,757] Trial 19 finished with value: 0.11202564835548401 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00014138534831825068}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:23,904] Trial 20 finished with value: 0.28638342022895813 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 128, 'learning_rate': 0.004524581966586933}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:28,351] Trial 21 finished with value: 0.11429737508296967 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00014543744415795065}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:33,224] Trial 22 finished with value: 0.15914300084114075 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00012758218477570342}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:37,583] Trial 23 finished with value: 0.20908404886722565 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0005118583452032021}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:41,376] Trial 24 finished with value: 0.21409127116203308 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00016252049493804114}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:45,710] Trial 25 finished with value: 0.3210115134716034 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 2.8392967241184104e-05}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:50,581] Trial 26 finished with value: 0.2602822184562683 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0023208101537045495}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:53,887] Trial 27 finished with value: 0.21690712869167328 and parameters: {'num_blocks': 5, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0005830840096011046}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:50:57,740] Trial 28 finished with value: 0.15202172100543976 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 128, 'learning_rate': 9.140808804367516e-05}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:01,430] Trial 29 finished with value: 0.1784633845090866 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00022754323777728907}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:03,597] Trial 30 finished with value: 0.25518184900283813 and parameters: {'num_blocks': 3, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 128, 'learning_rate': 3.468221656105346e-05}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:07,516] Trial 31 finished with value: 0.1710592359304428 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.009177714921881248}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:11,852] Trial 32 finished with value: 0.13389553129673004 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00018365761290734328}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:15,816] Trial 33 finished with value: 0.14737339317798615 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 32, 'learning_rate': 5.3071569392974035e-05}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:20,237] Trial 34 finished with value: 0.1469535380601883 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 64, 'learning_rate': 0.00013071361104201957}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:23,022] Trial 35 finished with value: 0.329345703125 and parameters: {'num_blocks': 5, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 32, 'learning_rate': 1.91864404911443e-05}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:26,770] Trial 36 finished with value: 0.15713851153850555 and parameters: {'num_blocks': 6, 'token_mix_hidden_dim': 64, 'channel_mix_hidden_dim': 64, 'learning_rate': 8.286746624826896e-05}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:31,940] Trial 37 finished with value: 0.12321651726961136 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00024214019785589094}. Best is trial 19 with value: 0.11202564835548401.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:37,174] Trial 38 finished with value: 0.0960722267627716 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0002383069428337443}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:42,405] Trial 39 finished with value: 0.18756362795829773 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0005104304830116932}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:45,324] Trial 40 finished with value: 0.13850761950016022 and parameters: {'num_blocks': 4, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 64, 'learning_rate': 0.00026828273059511165}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:50,528] Trial 41 finished with value: 0.22099284827709198 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.00014675264349314155}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:55,572] Trial 42 finished with value: 0.17530150711536407 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 5.942699917041121e-05}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:51:59,994] Trial 43 finished with value: 0.27301153540611267 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0004241478875470466}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:52:05,185] Trial 44 finished with value: 0.20058102905750275 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.000248317937222783}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:52:09,583] Trial 45 finished with value: 0.12578825652599335 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 9.491677605666401e-05}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:52:14,491] Trial 46 finished with value: 0.14190590381622314 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 0.0002890059398901103}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:52:15,466] Trial 47 finished with value: 0.1379431188106537 and parameters: {'num_blocks': 1, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 128, 'learning_rate': 0.0006530278141571927}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:52:19,799] Trial 48 finished with value: 0.22439368069171906 and parameters: {'num_blocks': 7, 'token_mix_hidden_dim': 128, 'channel_mix_hidden_dim': 32, 'learning_rate': 3.989734494200152e-05}. Best is trial 38 with value: 0.0960722267627716.\n",
      "<ipython-input-18-06187830d250>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "<ipython-input-6-1e5ce8616122>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_x = torch.tensor(x_train, dtype=torch.float32)\n",
      "<ipython-input-6-1e5ce8616122>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data_y = torch.tensor(y_train, dtype=torch.float32)\n",
      "[I 2024-12-05 21:52:24,226] Trial 49 finished with value: 0.26674240827560425 and parameters: {'num_blocks': 8, 'token_mix_hidden_dim': 32, 'channel_mix_hidden_dim': 64, 'learning_rate': 6.725129191750612e-05}. Best is trial 38 with value: 0.0960722267627716.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (Val Loss): 0.0960722267627716\n",
      "  Params: \n",
      "    num_blocks: 8\n",
      "    token_mix_hidden_dim: 128\n",
      "    channel_mix_hidden_dim: 32\n",
      "    learning_rate: 0.0002383069428337443\n",
      "\n",
      "Best Trial Metrics:\n",
      "  Accuracy: 0.9824561403508771\n",
      "  AUC: 0.9912337662337662\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), \n",
    "                        columns=X.columns, \n",
    "                        index=X.index)\n",
    "# Assign the value of 1 to Malignant, assign 0 to Benign\n",
    "Y.loc[:, 'Diagnosis'] = Y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Split the data - 60/20/20 Train Validation Test Split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', \n",
    "                             study_name='MLP Mixer Optimization')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (Val Loss): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Print additional metrics from the best trial\n",
    "print(\"\\nBest Trial Metrics:\")\n",
    "print(f\"  Accuracy: {trial.user_attrs['accuracy']}\")\n",
    "print(f\"  AUC: {trial.user_attrs['auc']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly, evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the best trial's parameters\n",
    "best_params = study.best_trial.params\n",
    "best_no_of_blocks = best_params['num_blocks']\n",
    "best_token_mix_hidden_dim = best_params['token_mix_hidden_dim']\n",
    "best_channel_mix_hidden_dim = best_params['channel_mix_hidden_dim']\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "\n",
    "best_model = MLP_Mixer(best_no_of_blocks, best_token_mix_hidden_dim, best_channel_mix_hidden_dim)\n",
    "\n",
    "# Convert train and validation data to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Create optimizer with the best learning rate\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Retrain the model with best hyperparameters\n",
    "# Batching is not implemented. \n",
    "# The whole training dataset is processed in a single pass. \n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = best_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Convert test data to tensors\n",
    "X_test_tensor = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predictions\n",
    "    test_outputs = best_model(X_test_tensor)\n",
    "    test_preds = (test_outputs > 0.5).float()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds.numpy())\n",
    "    test_auc = roc_auc_score(y_test, test_outputs.numpy())\n",
    "    \n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_preds.numpy())\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, test_preds.numpy())\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "Test Loss: 0.24762921035289764\n",
      "Test Accuracy: 0.9736842105263158\n",
      "Test AUC: 0.9954143465443827\n",
      "\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 3 40]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        71\n",
      "           1       1.00      0.93      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test AUC: {test_auc}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
